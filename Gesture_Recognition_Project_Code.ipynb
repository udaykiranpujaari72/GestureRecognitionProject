{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages (from imageio) (1.24.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages (from imageio) (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "#resize\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(image, crop_fraction):\n",
    "    \"\"\"\n",
    "    Crop the image by a certain fraction of its width, maintaining the center.\n",
    "    The crop_fraction should be a float representing the fraction of the width to crop.\n",
    "    The image's RGB channels will be preserved.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: numpy array of shape (height, width, channels), representing the image.\n",
    "    - crop_fraction: float, the fraction of the image's width to crop (0.10 means cropping 10% from both sides).\n",
    "    \n",
    "    Returns:\n",
    "    - cropped_image: numpy array of the cropped image.\n",
    "    \"\"\"\n",
    "    # Ensure the image has 3 channels (RGB)\n",
    "    if image.shape[2] != 3:\n",
    "        raise ValueError(\"Image should have 3 channels (RGB).\")\n",
    "\n",
    "    # Get the height, width, and channels of the image\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    # Calculate the width to crop from each side\n",
    "    crop_w = int(crop_fraction * w)\n",
    "\n",
    "    # Determine the start and end indices for cropping\n",
    "    start_w = crop_w // 2\n",
    "    end_w = w - crop_w // 2\n",
    "\n",
    "    # Crop the image, preserving all RGB channels\n",
    "    cropped_image = image[:, start_w:end_w, :]\n",
    "\n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print('Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = list(range(30))  # We will use 30 frames per video (adjustable)\n",
    "    x, y, z = len(img_idx), 160, 160  # x is the number of images, y and z are the target dimensions\n",
    "\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)  # Shuffle the list of folders (videos)\n",
    "        num_batches = len(folder_list) // batch_size  # Calculate number of full batches\n",
    "        print('num_batches = ', num_batches)\n",
    "\n",
    "        for batch in range(num_batches):  # Iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size, x, y, z, 3))  # Initialize batch data (40 samples, 30 frames, 160x160, 3 channels)\n",
    "            batch_labels = np.zeros((batch_size, 5))  # Initialize batch labels (one-hot encoding for 5 classes)\n",
    "            \n",
    "            for folder in range(batch_size):  # Iterate over the batch size (40 samples)\n",
    "                folder_path = source_path + '/' + t[folder + (batch * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over the frames/images (using img_idx)\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n",
    "                    \n",
    "                    # Crop and resize images to ensure uniformity in shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL \n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image by mean normalization (subtract mean and divide by standard deviation)\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the label (class)\n",
    "                class_idx = int(t[folder + (batch * batch_size)].strip().split(';')[2])  # Get the class index from the CSV file\n",
    "                batch_labels[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "\n",
    "            yield batch_data, batch_labels  # Yield the batch of data and labels\n",
    "\n",
    "        # Handle remaining data points (if not a perfect multiple of batch_size)\n",
    "        if len(folder_list) % batch_size != 0:\n",
    "            remaining_samples = len(folder_list) % batch_size\n",
    "            batch_data_remaining = np.zeros((remaining_samples, x, y, z, 3))  # Remaining batch data\n",
    "            batch_labels_remaining = np.zeros((remaining_samples, 5))  # Remaining batch labels\n",
    "\n",
    "            for folder in range(remaining_samples):  # Process the remaining samples\n",
    "                folder_path = source_path + '/' + t[folder + (num_batches * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over frames/images of a folder\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image\n",
    "\n",
    "                    # Crop and resize the images to ensure uniform shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL\n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the class\n",
    "                class_idx = int(t[folder + (num_batches * batch_size)].strip().split(';')[2])\n",
    "                batch_labels_remaining[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "\n",
    "            yield batch_data_remaining, batch_labels_remaining  # Yield the final batch with the remaining data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1\n",
    "\n",
    "Conv 3D Model with 30 epochs, 40 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 160x160 , adam optimiser with learning rate 0.0001, 30 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, MaxPooling3D, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 3D Convolutional Layers and Max Pooling Layers\n",
    "# Input shape is (30, 160, 160, 3) -> (number of frames, height, width, channels)\n",
    "\n",
    "# First Conv3D layer\n",
    "model.add(Conv3D(16, (3, 3, 3), padding='same', input_shape=(30, 160, 160, 3)))  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Second Conv3D layer\n",
    "model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Third Conv3D layer\n",
    "model.add(Conv3D(64, (3, 3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Flatten the output of Conv3D layers before passing to fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer for Classification\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output Layer (5 classes for classification)\n",
    "model.add(Dense(5, activation='softmax'))  # Assuming there are 5 classes for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,830,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │         \u001b[38;5;34m1,312\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m16\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m13,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m) │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m55,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m9,830,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,902,149</span> (37.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,902,149\u001b[0m (37.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,901,925</span> (37.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,901,925\u001b[0m (37.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "# Save the model in .keras format during training\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.weights.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, save_weights_only=True, mode='auto',  save_freq='epoch')\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', \n",
    "                       factor=0.2, \n",
    "                       patience=5, \n",
    "                       verbose=1, \n",
    "                       min_lr=0.0001)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 17\n",
      "Validation steps: 3\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 40\n",
      "num_batches =  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_10673/1150823310.py:21: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m59s\u001b[0m 30s/step - categorical_accuracy: 0.2098 - loss: 6.0074 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_10673/1150823310.py:58: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 29s/step - categorical_accuracy: 0.2136 - loss: 5.8725num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.2166 - loss: 5.7489 Source path =  Project_data/val ; batch size = 40\n",
      "num_batches =  2\n",
      "num_batches =  2\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2608_18_45.693183/model-00001-3.77187-0.26546-1.53121-0.31000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 30s/step - categorical_accuracy: 0.2193 - loss: 5.6391 - val_categorical_accuracy: 0.3100 - val_loss: 1.5312 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m57s\u001b[0m 57s/step - categorical_accuracy: 0.5335 - loss: 1.1130 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54s/step - categorical_accuracy: 0.5356 - loss: 1.1121 num_batches =  2\n",
      "\n",
      "Epoch 2: saving model to model_init_2024-12-2608_18_45.693183/model-00002-1.09797-0.56863-1.48434-0.32500.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 55s/step - categorical_accuracy: 0.5374 - loss: 1.1113 - val_categorical_accuracy: 0.3250 - val_loss: 1.4843 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m34s\u001b[0m 35s/step - categorical_accuracy: 0.6787 - loss: 0.8648 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33s/step - categorical_accuracy: 0.6787 - loss: 0.8637 num_batches =  2\n",
      "\n",
      "Epoch 3: saving model to model_init_2024-12-2608_18_45.693183/model-00003-0.84620-0.67873-1.39068-0.44167.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 34s/step - categorical_accuracy: 0.6787 - loss: 0.8627 - val_categorical_accuracy: 0.4417 - val_loss: 1.3907 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 31s/step - categorical_accuracy: 0.8110 - loss: 0.5918 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - categorical_accuracy: 0.8087 - loss: 0.5940 num_batches =  2\n",
      "\n",
      "Epoch 4: saving model to model_init_2024-12-2608_18_45.693183/model-00004-0.62851-0.77074-1.43532-0.35000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 32s/step - categorical_accuracy: 0.8066 - loss: 0.5959 - val_categorical_accuracy: 0.3500 - val_loss: 1.4353 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 0.8002 - loss: 0.5535num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.8003 - loss: 0.5540 \n",
      "Epoch 5: saving model to model_init_2024-12-2608_18_45.693183/model-00005-0.56248-0.80090-1.36075-0.43333.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 30s/step - categorical_accuracy: 0.8003 - loss: 0.5545 - val_categorical_accuracy: 0.4333 - val_loss: 1.3607 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m32s\u001b[0m 33s/step - categorical_accuracy: 0.9483 - loss: 0.3154 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - categorical_accuracy: 0.9463 - loss: 0.3186 num_batches =  2\n",
      "\n",
      "Epoch 6: saving model to model_init_2024-12-2608_18_45.693183/model-00006-0.36845-0.91403-1.39711-0.44167.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 33s/step - categorical_accuracy: 0.9445 - loss: 0.3213 - val_categorical_accuracy: 0.4417 - val_loss: 1.3971 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m35s\u001b[0m 35s/step - categorical_accuracy: 0.9763 - loss: 0.2575 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - categorical_accuracy: 0.9739 - loss: 0.2603 num_batches =  2\n",
      "\n",
      "Epoch 7: saving model to model_init_2024-12-2608_18_45.693183/model-00007-0.30638-0.93514-1.36526-0.36667.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 35s/step - categorical_accuracy: 0.9717 - loss: 0.2629 - val_categorical_accuracy: 0.3667 - val_loss: 1.3653 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m33s\u001b[0m 33s/step - categorical_accuracy: 0.9879 - loss: 0.1897 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32s/step - categorical_accuracy: 0.9858 - loss: 0.1928 num_batches =  2\n",
      "\n",
      "Epoch 8: saving model to model_init_2024-12-2608_18_45.693183/model-00008-0.24137-0.95173-1.76336-0.32000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 33s/step - categorical_accuracy: 0.9839 - loss: 0.1955 - val_categorical_accuracy: 0.3200 - val_loss: 1.7634 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 0.9937 - loss: 0.1593num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9917 - loss: 0.1623 num_batches =  2\n",
      "\n",
      "Epoch 9: saving model to model_init_2024-12-2608_18_45.693183/model-00009-0.21016-0.95928-1.53159-0.38333.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 30s/step - categorical_accuracy: 0.9899 - loss: 0.1650 - val_categorical_accuracy: 0.3833 - val_loss: 1.5316 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m30s\u001b[0m 31s/step - categorical_accuracy: 0.9939 - loss: 0.1245 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - categorical_accuracy: 0.9926 - loss: 0.1273 \n",
      "Epoch 10: saving model to model_init_2024-12-2608_18_45.693183/model-00010-0.17363-0.97134-1.39346-0.40000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 30s/step - categorical_accuracy: 0.9914 - loss: 0.1299 - val_categorical_accuracy: 0.4000 - val_loss: 1.3935 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m34s\u001b[0m 34s/step - categorical_accuracy: 0.9991 - loss: 0.1136 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33s/step - categorical_accuracy: 0.9974 - loss: 0.1161 num_batches =  2\n",
      "\n",
      "Epoch 11: saving model to model_init_2024-12-2608_18_45.693183/model-00011-0.15557-0.96983-1.59277-0.35833.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 34s/step - categorical_accuracy: 0.9959 - loss: 0.1183 - val_categorical_accuracy: 0.3583 - val_loss: 1.5928 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0775num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9985 - loss: 0.0806 num_batches =  2\n",
      "\n",
      "Epoch 12: saving model to model_init_2024-12-2608_18_45.693183/model-00012-0.13027-0.97436-1.60566-0.36667.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 30s/step - categorical_accuracy: 0.9972 - loss: 0.0833 - val_categorical_accuracy: 0.3667 - val_loss: 1.6057 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0605num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9984 - loss: 0.0638 num_batches =  2\n",
      "\n",
      "Epoch 13: saving model to model_init_2024-12-2608_18_45.693183/model-00013-0.11534-0.97285-2.22640-0.32000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 29s/step - categorical_accuracy: 0.9970 - loss: 0.0666 - val_categorical_accuracy: 0.3200 - val_loss: 2.2264 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m30s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0499 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9984 - loss: 0.0531 \n",
      "Epoch 14: saving model to model_init_2024-12-2608_18_45.693183/model-00014-0.10426-0.97285-1.35867-0.49167.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 30s/step - categorical_accuracy: 0.9970 - loss: 0.0560 - val_categorical_accuracy: 0.4917 - val_loss: 1.3587 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0447num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9987 - loss: 0.0479 num_batches =  2\n",
      "\n",
      "Epoch 15: saving model to model_init_2024-12-2608_18_45.693183/model-00015-0.09852-0.97738-1.48156-0.49167.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 29s/step - categorical_accuracy: 0.9975 - loss: 0.0507 - val_categorical_accuracy: 0.4917 - val_loss: 1.4816 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m30s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0394 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9983 - loss: 0.0426 num_batches =  2\n",
      "\n",
      "Epoch 16: saving model to model_init_2024-12-2608_18_45.693183/model-00016-0.09430-0.97134-1.48382-0.51667.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 30s/step - categorical_accuracy: 0.9968 - loss: 0.0455 - val_categorical_accuracy: 0.5167 - val_loss: 1.4838 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 32s/step - categorical_accuracy: 1.0000 - loss: 0.0332 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31s/step - categorical_accuracy: 0.9984 - loss: 0.0364 num_batches =  2\n",
      "\n",
      "Epoch 17: saving model to model_init_2024-12-2608_18_45.693183/model-00017-0.08839-0.97285-1.46933-0.55000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 32s/step - categorical_accuracy: 0.9970 - loss: 0.0393 - val_categorical_accuracy: 0.5500 - val_loss: 1.4693 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 30s/step - categorical_accuracy: 1.0000 - loss: 0.0291num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9981 - loss: 0.0324 num_batches =  2\n",
      "\n",
      "Epoch 18: saving model to model_init_2024-12-2608_18_45.693183/model-00018-0.08372-0.96833-2.26316-0.46000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 30s/step - categorical_accuracy: 0.9965 - loss: 0.0352 - val_categorical_accuracy: 0.4600 - val_loss: 2.2632 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m35s\u001b[0m 35s/step - categorical_accuracy: 1.0000 - loss: 0.0267 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - categorical_accuracy: 0.9982 - loss: 0.0300 num_batches =  2\n",
      "\n",
      "Epoch 19: saving model to model_init_2024-12-2608_18_45.693183/model-00019-0.08232-0.96983-1.52395-0.55833.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 35s/step - categorical_accuracy: 0.9966 - loss: 0.0329 - val_categorical_accuracy: 0.5583 - val_loss: 1.5240 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 0.0231num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9982 - loss: 0.0264 num_batches =  2\n",
      "\n",
      "Epoch 20: saving model to model_init_2024-12-2608_18_45.693183/model-00020-0.07921-0.96983-1.45476-0.61667.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 29s/step - categorical_accuracy: 0.9966 - loss: 0.0293 - val_categorical_accuracy: 0.6167 - val_loss: 1.4548 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m30s\u001b[0m 31s/step - categorical_accuracy: 1.0000 - loss: 0.0230 num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29s/step - categorical_accuracy: 0.9982 - loss: 0.0262 \n",
      "Epoch 21: saving model to model_init_2024-12-2608_18_45.693183/model-00021-0.07737-0.96983-1.42438-0.64167.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 30s/step - categorical_accuracy: 0.9966 - loss: 0.0291 - val_categorical_accuracy: 0.6417 - val_loss: 1.4244 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 0.0193num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9985 - loss: 0.0226 num_batches =  2\n",
      "\n",
      "Epoch 22: saving model to model_init_2024-12-2608_18_45.693183/model-00022-0.07439-0.97436-1.50454-0.59167.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 29s/step - categorical_accuracy: 0.9972 - loss: 0.0254 - val_categorical_accuracy: 0.5917 - val_loss: 1.5045 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 0.0179num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9986 - loss: 0.0212 num_batches =  2\n",
      "\n",
      "Epoch 23: saving model to model_init_2024-12-2608_18_45.693183/model-00023-0.07305-0.97587-1.44459-0.60833.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 29s/step - categorical_accuracy: 0.9973 - loss: 0.0241 - val_categorical_accuracy: 0.6083 - val_loss: 1.4446 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 0.0157num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9981 - loss: 0.0190 num_batches =  2\n",
      "\n",
      "Epoch 24: saving model to model_init_2024-12-2608_18_45.693183/model-00024-0.07148-0.96833-1.48005-0.63333.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 28s/step - categorical_accuracy: 0.9965 - loss: 0.0219 - val_categorical_accuracy: 0.6333 - val_loss: 1.4800 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 0.0163num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9986 - loss: 0.0195 num_batches =  2\n",
      "\n",
      "Epoch 25: saving model to model_init_2024-12-2608_18_45.693183/model-00025-0.07082-0.97587-2.35649-0.52000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 28s/step - categorical_accuracy: 0.9973 - loss: 0.0224 - val_categorical_accuracy: 0.5200 - val_loss: 2.3565 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 0.0139num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9982 - loss: 0.0171 \n",
      "Epoch 26: saving model to model_init_2024-12-2608_18_45.693183/model-00026-0.06830-0.96983-1.54416-0.60833.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 28s/step - categorical_accuracy: 0.9966 - loss: 0.0200 - val_categorical_accuracy: 0.6083 - val_loss: 1.5442 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 0.0117num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9985 - loss: 0.0150 num_batches =  2\n",
      "\n",
      "Epoch 27: saving model to model_init_2024-12-2608_18_45.693183/model-00027-0.06714-0.97436-1.70764-0.60833.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 28s/step - categorical_accuracy: 0.9972 - loss: 0.0179 - val_categorical_accuracy: 0.6083 - val_loss: 1.7076 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 0.0107num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9983 - loss: 0.0139 num_batches =  2\n",
      "\n",
      "Epoch 28: saving model to model_init_2024-12-2608_18_45.693183/model-00028-0.06623-0.97134-1.78517-0.58333.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 28s/step - categorical_accuracy: 0.9968 - loss: 0.0168 - val_categorical_accuracy: 0.5833 - val_loss: 1.7852 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 0.0099num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9982 - loss: 0.0132 num_batches =  2\n",
      "\n",
      "Epoch 29: saving model to model_init_2024-12-2608_18_45.693183/model-00029-0.06587-0.96983-1.71330-0.60000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 29s/step - categorical_accuracy: 0.9966 - loss: 0.0161 - val_categorical_accuracy: 0.6000 - val_loss: 1.7133 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 0.0094num_batches =  16\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9983 - loss: 0.0126 num_batches =  2\n",
      "\n",
      "Epoch 30: saving model to model_init_2024-12-2608_18_45.693183/model-00030-0.06507-0.97134-2.79378-0.47000.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 28s/step - categorical_accuracy: 0.9968 - loss: 0.0156 - val_categorical_accuracy: 0.4700 - val_loss: 2.7938 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x304be8dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 47 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - 2\n",
    "Conv 3D Model with 15 epochs, 25 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 120x120 , adam optimiser with learning rate 0.0001, 18 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_2(source_path, folder_list, batch_size):\n",
    "    print('Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
    "    #list(range(30))  # We will use 30 frames per video (adjustable)\n",
    "    x, y, z = len(img_idx), 120, 120  # x is the number of images, y and z are the target dimensions\n",
    "\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)  # Shuffle the list of folders (videos)\n",
    "        num_batches = len(folder_list) // batch_size  # Calculate number of full batches\n",
    "        print('num_batches = ', num_batches)\n",
    "\n",
    "        for batch in range(num_batches):  # Iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size, x, y, z, 3))  # Initialize batch data (40 samples, 30 frames, 160x160, 3 channels)\n",
    "            batch_labels = np.zeros((batch_size, 5))  # Initialize batch labels (one-hot encoding for 5 classes)\n",
    "            \n",
    "            for folder in range(batch_size):  # Iterate over the batch size (40 samples)\n",
    "                folder_path = source_path + '/' + t[folder + (batch * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over the frames/images (using img_idx)\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n",
    "                    \n",
    "                    # Crop and resize images to ensure uniformity in shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL \n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image by mean normalization (subtract mean and divide by standard deviation)\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the label (class)\n",
    "                class_idx = int(t[folder + (batch * batch_size)].strip().split(';')[2])  # Get the class index from the CSV file\n",
    "                batch_labels[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "\n",
    "            yield batch_data, batch_labels  # Yield the batch of data and labels\n",
    "\n",
    "        # Handle remaining data points (if not a perfect multiple of batch_size)\n",
    "        if len(folder_list) % batch_size != 0:\n",
    "            remaining_samples = len(folder_list) % batch_size\n",
    "            batch_data_remaining = np.zeros((remaining_samples, x, y, z, 3))  # Remaining batch data\n",
    "            batch_labels_remaining = np.zeros((remaining_samples, 5))  # Remaining batch labels\n",
    "\n",
    "            for folder in range(remaining_samples):  # Process the remaining samples\n",
    "                folder_path = source_path + '/' + t[folder + (num_batches * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over frames/images of a folder\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image\n",
    "\n",
    "                    # Crop and resize the images to ensure uniform shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL\n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the class\n",
    "                class_idx = int(t[folder + (num_batches * batch_size)].strip().split(';')[2])\n",
    "                batch_labels_remaining[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "\n",
    "            yield batch_data_remaining, batch_labels_remaining  # Yield the final batch with the remaining data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 15\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 25\n",
    "num_epochs = 15\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, BatchNormalization, Activation, Dropout, GlobalAveragePooling3D, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "dropout_rate = 0.5\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# First Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    16, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    input_shape=(18, 120, 120, 3), \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "# Second Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    32, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "# Third Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    64, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "# Global Average Pooling and Fully Connected Layers\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling3d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │         \u001b[38;5;34m1,312\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m16\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_3 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_4 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m13,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_4 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_5 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m55,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_5 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling3d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,941</span> (312.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,941\u001b[0m (312.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,717</span> (311.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,717\u001b[0m (311.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_2(train_path, train_doc, batch_size)\n",
    "val_generator = generator_2(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 27\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 25\n",
      "num_batches =  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_31353/4273982213.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 5s/step - categorical_accuracy: 0.2002 - loss: 3.4224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_31353/4273982213.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.2001 - loss: 3.4187 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.1999 - loss: 3.4151Source path =  Project_data/val ; batch size = 25\n",
      "num_batches =  4\n",
      "num_batches =  4\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2619_34_37.119648/model-00001-3.32135-0.19457-3.08584-0.22000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 6s/step - categorical_accuracy: 0.1997 - loss: 3.4117 - val_categorical_accuracy: 0.2200 - val_loss: 3.0858 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.2602 - loss: 3.1374 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.2600 - loss: 3.1374num_batches =  4\n",
      "\n",
      "Epoch 2: saving model to model_init_2024-12-2619_34_37.119648/model-00002-3.13861-0.25641-3.05300-0.24000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - categorical_accuracy: 0.2599 - loss: 3.1375 - val_categorical_accuracy: 0.2400 - val_loss: 3.0530 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3100 - loss: 3.0030 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3096 - loss: 3.0042num_batches =  4\n",
      "\n",
      "Epoch 3: saving model to model_init_2024-12-2619_34_37.119648/model-00003-3.03536-0.30015-3.02337-0.37000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - categorical_accuracy: 0.3093 - loss: 3.0053 - val_categorical_accuracy: 0.3700 - val_loss: 3.0234 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.2755 - loss: 3.0584 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.2756 - loss: 3.0576num_batches =  4\n",
      "\n",
      "Epoch 4: saving model to model_init_2024-12-2619_34_37.119648/model-00004-3.03566-0.27903-2.97751-0.30000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - categorical_accuracy: 0.2757 - loss: 3.0568 - val_categorical_accuracy: 0.3000 - val_loss: 2.9775 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3297 - loss: 2.9439 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3288 - loss: 2.9451num_batches =  4\n",
      "\n",
      "Epoch 5: saving model to model_init_2024-12-2619_34_37.119648/model-00005-2.97733-0.30468-2.94902-0.28000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3279 - loss: 2.9463 - val_categorical_accuracy: 0.2800 - val_loss: 2.9490 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3041 - loss: 2.9362 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3050 - loss: 2.9351num_batches =  4\n",
      "\n",
      "Epoch 6: saving model to model_init_2024-12-2619_34_37.119648/model-00006-2.90595-0.32881-2.94390-0.24000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3059 - loss: 2.9340 - val_categorical_accuracy: 0.2400 - val_loss: 2.9439 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3369 - loss: 2.8921 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3375 - loss: 2.8912num_batches =  4\n",
      "\n",
      "Epoch 7: saving model to model_init_2024-12-2619_34_37.119648/model-00007-2.86652-0.35445-2.87582-0.27000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3381 - loss: 2.8903 - val_categorical_accuracy: 0.2700 - val_loss: 2.8758 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3883 - loss: 2.8241 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3881 - loss: 2.8235num_batches =  4\n",
      "\n",
      "Epoch 8: saving model to model_init_2024-12-2619_34_37.119648/model-00008-2.80879-0.38462-2.85178-0.33000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3880 - loss: 2.8230 - val_categorical_accuracy: 0.3300 - val_loss: 2.8518 - learning_rate: 1.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3620 - loss: 2.7553 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3616 - loss: 2.7562num_batches =  4\n",
      "\n",
      "Epoch 9: saving model to model_init_2024-12-2619_34_37.119648/model-00009-2.77739-0.34992-2.81273-0.26000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3612 - loss: 2.7569 - val_categorical_accuracy: 0.2600 - val_loss: 2.8127 - learning_rate: 1.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.3856 - loss: 2.7835 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.3857 - loss: 2.7826num_batches =  4\n",
      "\n",
      "Epoch 10: saving model to model_init_2024-12-2619_34_37.119648/model-00010-2.75917-0.38612-2.72810-0.32000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.3857 - loss: 2.7818 - val_categorical_accuracy: 0.3200 - val_loss: 2.7281 - learning_rate: 1.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.4263 - loss: 2.6650 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.4257 - loss: 2.6660num_batches =  4\n",
      "\n",
      "Epoch 11: saving model to model_init_2024-12-2619_34_37.119648/model-00011-2.69236-0.41026-2.69949-0.40000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.4251 - loss: 2.6670 - val_categorical_accuracy: 0.4000 - val_loss: 2.6995 - learning_rate: 1.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.4698 - loss: 2.6558 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.4679 - loss: 2.6553num_batches =  4\n",
      "\n",
      "Epoch 12: saving model to model_init_2024-12-2619_34_37.119648/model-00012-2.64275-0.41780-2.62162-0.49000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.4661 - loss: 2.6549 - val_categorical_accuracy: 0.4900 - val_loss: 2.6216 - learning_rate: 1.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.4186 - loss: 2.6199 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.4183 - loss: 2.6206num_batches =  4\n",
      "\n",
      "Epoch 13: saving model to model_init_2024-12-2619_34_37.119648/model-00013-2.63983-0.41176-2.55019-0.54000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.4181 - loss: 2.6213 - val_categorical_accuracy: 0.5400 - val_loss: 2.5502 - learning_rate: 1.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.4591 - loss: 2.5573 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.4593 - loss: 2.5573num_batches =  4\n",
      "\n",
      "Epoch 14: saving model to model_init_2024-12-2619_34_37.119648/model-00014-2.55791-0.46456-2.51566-0.49000.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.4595 - loss: 2.5573 - val_categorical_accuracy: 0.4900 - val_loss: 2.5157 - learning_rate: 1.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 5s/step - categorical_accuracy: 0.4580 - loss: 2.5370 num_batches =  26\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.4578 - loss: 2.5377num_batches =  4\n",
      "\n",
      "Epoch 15: saving model to model_init_2024-12-2619_34_37.119648/model-00015-2.55539-0.45249-2.43803-0.51000.keras\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - categorical_accuracy: 0.4576 - loss: 2.5383 - val_categorical_accuracy: 0.5100 - val_loss: 2.4380 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x309bffc50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 45 % and validation accuracy of 51 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - 3\n",
    "Conv 3D Model with 20 epochs, 30 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 120x120 , adam optimiser with learning rate 0.0001, 18 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "#train_doc = np.random.permutation(open('Project_data_Final/train_100.csv').readlines())\n",
    "#val_doc = np.random.permutation(open('Project_data_Final/val_50.csv').readlines())\n",
    "\n",
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "batch_size = 30\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, BatchNormalization, Activation, Dropout, GlobalAveragePooling3D, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# First Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    16, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    input_shape=(18, 120, 120, 3), \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Second Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    32, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Third Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    64, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Global Average Pooling and Fully Connected Layers\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling3d_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_18 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │           \u001b[38;5;34m1,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_18 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_18 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_19 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │          \u001b[38;5;34m13,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_19 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_19 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_20 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m55,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_20 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_20 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling3d_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,941</span> (312.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,941\u001b[0m (312.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,717</span> (311.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,717\u001b[0m (311.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_2(train_path, train_doc, batch_size)\n",
    "val_generator = generator_2(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 23\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data_Final/train ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\669548316.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.1950 - loss: 3.3500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\669548316.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.1969 - loss: 3.3429Source path =  Project_data_Final/val ; batch size = 30\n",
      "num_batches =  3\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2619_21_51.635635/model-00001-3.26843-0.21719-3.13768-0.18000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 4s/step - categorical_accuracy: 0.1977 - loss: 3.3398 - val_categorical_accuracy: 0.1800 - val_loss: 3.1377 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.3225 - loss: 3.0582 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.3239 - loss: 3.0559num_batches =  3\n",
      "\n",
      "Epoch 2: saving model to model_init_2024-12-2619_21_51.635635/model-00002-3.03176-0.33786-3.08669-0.28000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - categorical_accuracy: 0.3244 - loss: 3.0549 - val_categorical_accuracy: 0.2800 - val_loss: 3.0867 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.3848 - loss: 2.9214 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.3847 - loss: 2.9198num_batches =  3\n",
      "\n",
      "Epoch 3: saving model to model_init_2024-12-2619_21_51.635635/model-00003-2.90378-0.38311-3.02098-0.23000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - categorical_accuracy: 0.3847 - loss: 2.9192 - val_categorical_accuracy: 0.2300 - val_loss: 3.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.4712 - loss: 2.8203 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.4731 - loss: 2.8182num_batches =  3\n",
      "\n",
      "Epoch 4: saving model to model_init_2024-12-2619_21_51.635635/model-00004-2.79659-0.49321-3.03831-0.19000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - categorical_accuracy: 0.4739 - loss: 2.8173 - val_categorical_accuracy: 0.1900 - val_loss: 3.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.5790 - loss: 2.6902 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.5768 - loss: 2.6899num_batches =  3\n",
      "\n",
      "Epoch 5: saving model to model_init_2024-12-2619_21_51.635635/model-00005-2.68721-0.55354-3.01732-0.20000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - categorical_accuracy: 0.5758 - loss: 2.6898 - val_categorical_accuracy: 0.2000 - val_loss: 3.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.5735 - loss: 2.6089 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.5761 - loss: 2.6065num_batches =  3\n",
      "\n",
      "Epoch 6: saving model to model_init_2024-12-2619_21_51.635635/model-00006-2.58166-0.60332-3.03096-0.14000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - categorical_accuracy: 0.5773 - loss: 2.6055 - val_categorical_accuracy: 0.1400 - val_loss: 3.0310 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.6543 - loss: 2.4979 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.6548 - loss: 2.4959num_batches =  3\n",
      "\n",
      "Epoch 7: saving model to model_init_2024-12-2619_21_51.635635/model-00007-2.47571-0.65913-3.10351-0.17000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - categorical_accuracy: 0.6549 - loss: 2.4950 - val_categorical_accuracy: 0.1700 - val_loss: 3.1035 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.6841 - loss: 2.3816 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.6833 - loss: 2.3811num_batches =  3\n",
      "\n",
      "Epoch 8: saving model to model_init_2024-12-2619_21_51.635635/model-00008-2.37750-0.67421-3.03366-0.18000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - categorical_accuracy: 0.6830 - loss: 2.3810 - val_categorical_accuracy: 0.1800 - val_loss: 3.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.7106 - loss: 2.3182 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.7119 - loss: 2.3149num_batches =  3\n",
      "\n",
      "Epoch 9: saving model to model_init_2024-12-2619_21_51.635635/model-00009-2.28147-0.72398-2.98040-0.23000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 4s/step - categorical_accuracy: 0.7124 - loss: 2.3135 - val_categorical_accuracy: 0.2300 - val_loss: 2.9804 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.7759 - loss: 2.1622 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.7729 - loss: 2.1637num_batches =  3\n",
      "\n",
      "Epoch 10: saving model to model_init_2024-12-2619_21_51.635635/model-00010-2.18052-0.74057-2.94854-0.24000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - categorical_accuracy: 0.7716 - loss: 2.1644 - val_categorical_accuracy: 0.2400 - val_loss: 2.9485 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.7599 - loss: 2.1319 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.7605 - loss: 2.1304num_batches =  3\n",
      "\n",
      "Epoch 11: saving model to model_init_2024-12-2619_21_51.635635/model-00011-2.11548-0.76621-2.75585-0.33000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - categorical_accuracy: 0.7607 - loss: 2.1297 - val_categorical_accuracy: 0.3300 - val_loss: 2.7558 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.7774 - loss: 2.0191 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.7776 - loss: 2.0193num_batches =  3\n",
      "\n",
      "Epoch 12: saving model to model_init_2024-12-2619_21_51.635635/model-00012-2.02305-0.77828-2.68851-0.34000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - categorical_accuracy: 0.7776 - loss: 2.0194 - val_categorical_accuracy: 0.3400 - val_loss: 2.6885 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.8324 - loss: 1.9674 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8322 - loss: 1.9645num_batches =  3\n",
      "\n",
      "Epoch 13: saving model to model_init_2024-12-2619_21_51.635635/model-00013-1.93648-0.82805-2.60513-0.42000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - categorical_accuracy: 0.8320 - loss: 1.9634 - val_categorical_accuracy: 0.4200 - val_loss: 2.6051 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.8730 - loss: 1.8635 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8701 - loss: 1.8649num_batches =  3\n",
      "\n",
      "Epoch 14: saving model to model_init_2024-12-2619_21_51.635635/model-00014-1.88186-0.83861-2.46881-0.48000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 4s/step - categorical_accuracy: 0.8688 - loss: 1.8656 - val_categorical_accuracy: 0.4800 - val_loss: 2.4688 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.8403 - loss: 1.8607 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8404 - loss: 1.8579num_batches =  3\n",
      "\n",
      "Epoch 15: saving model to model_init_2024-12-2619_21_51.635635/model-00015-1.83107-0.84012-2.25662-0.60000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - categorical_accuracy: 0.8404 - loss: 1.8568 - val_categorical_accuracy: 0.6000 - val_loss: 2.2566 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.8511 - loss: 1.7743 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8513 - loss: 1.7734num_batches =  3\n",
      "\n",
      "Epoch 16: saving model to model_init_2024-12-2619_21_51.635635/model-00016-1.76598-0.85219-2.32655-0.46000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - categorical_accuracy: 0.8514 - loss: 1.7730 - val_categorical_accuracy: 0.4600 - val_loss: 2.3266 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.8782 - loss: 1.7134 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8770 - loss: 1.7138num_batches =  3\n",
      "\n",
      "Epoch 17: saving model to model_init_2024-12-2619_21_51.635635/model-00017-1.72020-0.86425-2.19753-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - categorical_accuracy: 0.8765 - loss: 1.7141 - val_categorical_accuracy: 0.5400 - val_loss: 2.1975 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 4s/step - categorical_accuracy: 0.8731 - loss: 1.6672 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8731 - loss: 1.6672num_batches =  3\n",
      "\n",
      "Epoch 18: saving model to model_init_2024-12-2619_21_51.635635/model-00018-1.66893-0.87179-2.09606-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - categorical_accuracy: 0.8730 - loss: 1.6673 - val_categorical_accuracy: 0.5600 - val_loss: 2.0961 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.8789 - loss: 1.6242 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8790 - loss: 1.6244num_batches =  3\n",
      "\n",
      "Epoch 19: saving model to model_init_2024-12-2619_21_51.635635/model-00019-1.62896-0.87783-1.85191-0.80000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - categorical_accuracy: 0.8789 - loss: 1.6246 - val_categorical_accuracy: 0.8000 - val_loss: 1.8519 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - categorical_accuracy: 0.8986 - loss: 1.5765 num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - categorical_accuracy: 0.8980 - loss: 1.5770num_batches =  3\n",
      "\n",
      "Epoch 20: saving model to model_init_2024-12-2619_21_51.635635/model-00020-1.58474-0.89140-1.82803-0.76000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - categorical_accuracy: 0.8978 - loss: 1.5773 - val_categorical_accuracy: 0.7600 - val_loss: 1.8280 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f104aa8910>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 89 % and validation accuracy of 76 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - 4\n",
    "Conv 3D Model with 50 epochs, 30 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 160x160 , adam optimiser with learning rate 0.0001, 18 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 50\n"
     ]
    }
   ],
   "source": [
    "#train_doc = np.random.permutation(open('Project_data_Final/train_100.csv').readlines())\n",
    "#val_doc = np.random.permutation(open('Project_data_Final/val_50.csv').readlines())\n",
    "\n",
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "batch_size = 30\n",
    "num_epochs = 50\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_3(source_path, folder_list, batch_size):\n",
    "    print('Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [0,1,2,4,5,6,8,9,10,12,14,16,18,20,22,24,26,27,28,29]\n",
    "    #list(range(30))  # We will use 30 frames per video (adjustable)\n",
    "    x, y, z = len(img_idx), 160, 160  # x is the number of images, y and z are the target dimensions\n",
    "\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)  # Shuffle the list of folders (videos)\n",
    "        num_batches = len(folder_list) // batch_size  # Calculate number of full batches\n",
    "        \n",
    "\n",
    "        for batch in range(num_batches):  # Iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size, x, y, z, 3))  # Initialize batch data (40 samples, 30 frames, 160x160, 3 channels)\n",
    "            batch_labels = np.zeros((batch_size, 5))  # Initialize batch labels (one-hot encoding for 5 classes)\n",
    "            \n",
    "            for folder in range(batch_size):  # Iterate over the batch size (40 samples)\n",
    "                folder_path = source_path + '/' + t[folder + (batch * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over the frames/images (using img_idx)\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n",
    "                    \n",
    "                    # Crop and resize images to ensure uniformity in shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL \n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image by mean normalization (subtract mean and divide by standard deviation)\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the label (class)\n",
    "                class_idx = int(t[folder + (batch * batch_size)].strip().split(';')[2])  # Get the class index from the CSV file\n",
    "                batch_labels[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "\n",
    "            yield batch_data, batch_labels  # Yield the batch of data and labels\n",
    "\n",
    "        # Handle remaining data points (if not a perfect multiple of batch_size)\n",
    "        if len(folder_list) % batch_size != 0:\n",
    "            remaining_samples = len(folder_list) % batch_size\n",
    "            batch_data_remaining = np.zeros((remaining_samples, x, y, z, 3))  # Remaining batch data\n",
    "            batch_labels_remaining = np.zeros((remaining_samples, 5))  # Remaining batch labels\n",
    "\n",
    "            for folder in range(remaining_samples):  # Process the remaining samples\n",
    "                folder_path = source_path + '/' + t[folder + (num_batches * batch_size)].split(';')[0]\n",
    "                imgs = os.listdir(folder_path)  # Read all image files in the folder\n",
    "\n",
    "                for idx, item in enumerate(img_idx):  # Iterate over frames/images of a folder\n",
    "                    img_path = os.path.join(folder_path, imgs[item])  # Get the image path\n",
    "                    image = imageio.imread(img_path).astype(np.float32)  # Read the image\n",
    "\n",
    "                    # Crop and resize the images to ensure uniform shape\n",
    "                    image = crop_img(image, 0.10)  # Crop 10% from both sides\n",
    "                    \n",
    "                    # Resize the image to 160x160 using PIL\n",
    "                    image = Image.fromarray(image.astype(np.uint8))  # Convert numpy array to PIL image\n",
    "                    image = image.resize((y, z), Image.Resampling.LANCZOS)  # Resize using Pillow\n",
    "                    image = np.array(image).astype(np.float32)  # Convert back to numpy array\n",
    "                    \n",
    "                    # Normalize the image\n",
    "                    image = (image - np.mean(image)) / np.std(image)  # Mean normalization\n",
    "\n",
    "                    # Load the image into the 3 RGB channels\n",
    "                    # Ensure we only store each colour channel separately\n",
    "                    batch_data[folder, idx, :, :, 0] = image[:, :, 0]  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image[:, :, 1]  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image[:, :, 2]  # Blue channel\n",
    "\n",
    "                # Set the one-hot encoding for the class\n",
    "                class_idx = int(t[folder + (num_batches * batch_size)].strip().split(';')[2])\n",
    "                batch_labels_remaining[folder, class_idx] = 1  # One-hot encoding for the class label\n",
    "                \n",
    "            yield batch_data_remaining, batch_labels_remaining  # Yield the final batch with the remaining data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, BatchNormalization, Activation, Dropout, GlobalAveragePooling3D, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# First Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    16, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    input_shape=(18, 160, 160, 3), \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Second Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    32, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Third Conv3D layer\n",
    "model.add(Conv3D(\n",
    "    64, \n",
    "    (3, 3, 3), \n",
    "    padding='same', \n",
    "    kernel_regularizer=regularizers.l2(l2_reg)\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Global Average Pooling and Fully Connected Layers\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling3d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling3D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv3d_21 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │           \u001b[38;5;34m1,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_21 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_21 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_22 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │          \u001b[38;5;34m13,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_22 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_22 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3d_23 (\u001b[38;5;33mConv3D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m55,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_23 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling3d_23 (\u001b[38;5;33mMaxPooling3D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling3d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling3D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,941</span> (312.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,941\u001b[0m (312.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,717</span> (311.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,717\u001b[0m (311.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_3(train_path, train_doc, batch_size)\n",
    "val_generator = generator_3(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 23\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data_Final/train ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.1887 - loss: 3.4841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.1910 - loss: 3.4673Source path =  Project_data_Final/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2619_21_51.635635/model-00001-3.29081-0.21418-3.13427-0.21000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 7s/step - categorical_accuracy: 0.1919 - loss: 3.4600 - val_categorical_accuracy: 0.2100 - val_loss: 3.1343 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.2971 - loss: 3.0345\n",
      "Epoch 2: saving model to model_init_2024-12-2619_21_51.635635/model-00002-3.02796-0.31523-3.08710-0.20000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 6s/step - categorical_accuracy: 0.2978 - loss: 3.0343 - val_categorical_accuracy: 0.2000 - val_loss: 3.0871 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.4299 - loss: 2.9267\n",
      "Epoch 3: saving model to model_init_2024-12-2619_21_51.635635/model-00003-2.90942-0.44193-3.03834-0.20000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 6s/step - categorical_accuracy: 0.4304 - loss: 2.9260 - val_categorical_accuracy: 0.2000 - val_loss: 3.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.5029 - loss: 2.8200\n",
      "Epoch 4: saving model to model_init_2024-12-2619_21_51.635635/model-00004-2.79054-0.52187-2.98196-0.22000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - categorical_accuracy: 0.5037 - loss: 2.8188 - val_categorical_accuracy: 0.2200 - val_loss: 2.9820 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.6061 - loss: 2.6685\n",
      "Epoch 5: saving model to model_init_2024-12-2619_21_51.635635/model-00005-2.66086-0.60483-2.93204-0.24000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - categorical_accuracy: 0.6061 - loss: 2.6681 - val_categorical_accuracy: 0.2400 - val_loss: 2.9320 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.6606 - loss: 2.5583\n",
      "Epoch 6: saving model to model_init_2024-12-2619_21_51.635635/model-00006-2.54696-0.65913-2.89216-0.21000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.6605 - loss: 2.5578 - val_categorical_accuracy: 0.2100 - val_loss: 2.8922 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.6915 - loss: 2.4733\n",
      "Epoch 7: saving model to model_init_2024-12-2619_21_51.635635/model-00007-2.44595-0.69532-2.87046-0.22000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - categorical_accuracy: 0.6916 - loss: 2.4722 - val_categorical_accuracy: 0.2200 - val_loss: 2.8705 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.7308 - loss: 2.3751\n",
      "Epoch 8: saving model to model_init_2024-12-2619_21_51.635635/model-00008-2.35060-0.74208-2.78284-0.35000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - categorical_accuracy: 0.7312 - loss: 2.3741 - val_categorical_accuracy: 0.3500 - val_loss: 2.7828 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.7808 - loss: 2.2594\n",
      "Epoch 9: saving model to model_init_2024-12-2619_21_51.635635/model-00009-2.26048-0.75113-2.68384-0.43000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.7795 - loss: 2.2595 - val_categorical_accuracy: 0.4300 - val_loss: 2.6838 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.7530 - loss: 2.2138\n",
      "Epoch 10: saving model to model_init_2024-12-2619_21_51.635635/model-00010-2.19675-0.75566-2.66900-0.36000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - categorical_accuracy: 0.7532 - loss: 2.2130 - val_categorical_accuracy: 0.3600 - val_loss: 2.6690 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8021 - loss: 2.0959\n",
      "Epoch 11: saving model to model_init_2024-12-2619_21_51.635635/model-00011-2.11058-0.78733-2.50419-0.52000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.8015 - loss: 2.0965 - val_categorical_accuracy: 0.5200 - val_loss: 2.5042 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8111 - loss: 2.0252\n",
      "Epoch 12: saving model to model_init_2024-12-2619_21_51.635635/model-00012-2.04197-0.79487-2.47674-0.51000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.8104 - loss: 2.0259 - val_categorical_accuracy: 0.5100 - val_loss: 2.4767 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8211 - loss: 1.9731\n",
      "Epoch 13: saving model to model_init_2024-12-2619_21_51.635635/model-00013-1.97287-0.80995-2.38611-0.60000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 6s/step - categorical_accuracy: 0.8206 - loss: 1.9731 - val_categorical_accuracy: 0.6000 - val_loss: 2.3861 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8177 - loss: 1.9572\n",
      "Epoch 14: saving model to model_init_2024-12-2619_21_51.635635/model-00014-1.92682-0.81297-2.40831-0.52000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.8175 - loss: 1.9559 - val_categorical_accuracy: 0.5200 - val_loss: 2.4083 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8475 - loss: 1.8859\n",
      "Epoch 15: saving model to model_init_2024-12-2619_21_51.635635/model-00015-1.87414-0.83409-2.28219-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - categorical_accuracy: 0.8469 - loss: 1.8854 - val_categorical_accuracy: 0.5400 - val_loss: 2.2822 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8453 - loss: 1.8210\n",
      "Epoch 16: saving model to model_init_2024-12-2619_21_51.635635/model-00016-1.82847-0.83861-2.08987-0.73000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - categorical_accuracy: 0.8451 - loss: 1.8213 - val_categorical_accuracy: 0.7300 - val_loss: 2.0899 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8439 - loss: 1.7956\n",
      "Epoch 17: saving model to model_init_2024-12-2619_21_51.635635/model-00017-1.77835-0.84465-1.99301-0.74000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.8440 - loss: 1.7949 - val_categorical_accuracy: 0.7400 - val_loss: 1.9930 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8307 - loss: 1.7505\n",
      "Epoch 18: saving model to model_init_2024-12-2619_21_51.635635/model-00018-1.74620-0.84615-2.02154-0.64000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.8314 - loss: 1.7504 - val_categorical_accuracy: 0.6400 - val_loss: 2.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8497 - loss: 1.7087\n",
      "Epoch 19: saving model to model_init_2024-12-2619_21_51.635635/model-00019-1.71976-0.83710-2.03290-0.67000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.8492 - loss: 1.7091 - val_categorical_accuracy: 0.6700 - val_loss: 2.0329 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8771 - loss: 1.6494\n",
      "Epoch 20: saving model to model_init_2024-12-2619_21_51.635635/model-00020-1.67746-0.85219-1.95625-0.74000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.8761 - loss: 1.6506 - val_categorical_accuracy: 0.7400 - val_loss: 1.9562 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8609 - loss: 1.6376\n",
      "Epoch 21: saving model to model_init_2024-12-2619_21_51.635635/model-00021-1.64720-0.86275-1.93372-0.71000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.8609 - loss: 1.6380 - val_categorical_accuracy: 0.7100 - val_loss: 1.9337 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8711 - loss: 1.5974\n",
      "Epoch 22: saving model to model_init_2024-12-2619_21_51.635635/model-00022-1.61317-0.86425-1.94129-0.65000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - categorical_accuracy: 0.8708 - loss: 1.5980 - val_categorical_accuracy: 0.6500 - val_loss: 1.9413 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8803 - loss: 1.5691\n",
      "Epoch 23: saving model to model_init_2024-12-2619_21_51.635635/model-00023-1.57575-0.87029-1.80881-0.79000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 6s/step - categorical_accuracy: 0.8799 - loss: 1.5694 - val_categorical_accuracy: 0.7900 - val_loss: 1.8088 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8955 - loss: 1.5265\n",
      "Epoch 24: saving model to model_init_2024-12-2619_21_51.635635/model-00024-1.55343-0.87783-1.73328-0.77000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 6s/step - categorical_accuracy: 0.8947 - loss: 1.5276 - val_categorical_accuracy: 0.7700 - val_loss: 1.7333 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8986 - loss: 1.4950\n",
      "Epoch 25: saving model to model_init_2024-12-2619_21_51.635635/model-00025-1.51947-0.87783-1.82180-0.73000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.8977 - loss: 1.4960 - val_categorical_accuracy: 0.7300 - val_loss: 1.8218 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8396 - loss: 1.5350\n",
      "Epoch 26: saving model to model_init_2024-12-2619_21_51.635635/model-00026-1.51149-0.86576-1.63247-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.8407 - loss: 1.5340 - val_categorical_accuracy: 0.8200 - val_loss: 1.6325 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8915 - loss: 1.4746\n",
      "Epoch 27: saving model to model_init_2024-12-2619_21_51.635635/model-00027-1.48430-0.87632-1.68816-0.76000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - categorical_accuracy: 0.8909 - loss: 1.4750 - val_categorical_accuracy: 0.7600 - val_loss: 1.6882 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9012 - loss: 1.4346\n",
      "Epoch 28: saving model to model_init_2024-12-2619_21_51.635635/model-00028-1.44859-0.88839-1.57673-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - categorical_accuracy: 0.9006 - loss: 1.4352 - val_categorical_accuracy: 0.8200 - val_loss: 1.5767 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9095 - loss: 1.4116\n",
      "Epoch 29: saving model to model_init_2024-12-2619_21_51.635635/model-00029-1.44162-0.89140-1.53508-0.85000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - categorical_accuracy: 0.9087 - loss: 1.4129 - val_categorical_accuracy: 0.8500 - val_loss: 1.5351 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9025 - loss: 1.4156\n",
      "Epoch 30: saving model to model_init_2024-12-2619_21_51.635635/model-00030-1.40680-0.89291-1.53395-0.83000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - categorical_accuracy: 0.9021 - loss: 1.4152 - val_categorical_accuracy: 0.8300 - val_loss: 1.5339 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.8969 - loss: 1.3698\n",
      "Epoch 31: saving model to model_init_2024-12-2619_21_51.635635/model-00031-1.38891-0.88688-1.56881-0.79000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.8965 - loss: 1.3706 - val_categorical_accuracy: 0.7900 - val_loss: 1.5688 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9038 - loss: 1.3503\n",
      "Epoch 32: saving model to model_init_2024-12-2619_21_51.635635/model-00032-1.35787-0.89894-1.50659-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9036 - loss: 1.3506 - val_categorical_accuracy: 0.8200 - val_loss: 1.5066 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9154 - loss: 1.3286\n",
      "Epoch 33: saving model to model_init_2024-12-2619_21_51.635635/model-00033-1.33529-0.91101-1.50995-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - categorical_accuracy: 0.9153 - loss: 1.3289 - val_categorical_accuracy: 0.8200 - val_loss: 1.5100 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9131 - loss: 1.3012\n",
      "Epoch 34: saving model to model_init_2024-12-2619_21_51.635635/model-00034-1.31253-0.90799-1.56363-0.77000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9129 - loss: 1.3017 - val_categorical_accuracy: 0.7700 - val_loss: 1.5636 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9294 - loss: 1.2834\n",
      "Epoch 35: saving model to model_init_2024-12-2619_21_51.635635/model-00035-1.28907-0.91855-1.54132-0.83000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - categorical_accuracy: 0.9289 - loss: 1.2837 - val_categorical_accuracy: 0.8300 - val_loss: 1.5413 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9128 - loss: 1.2714\n",
      "Epoch 36: saving model to model_init_2024-12-2619_21_51.635635/model-00036-1.28945-0.90950-1.50550-0.81000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.9126 - loss: 1.2721 - val_categorical_accuracy: 0.8100 - val_loss: 1.5055 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9319 - loss: 1.2412\n",
      "Epoch 37: saving model to model_init_2024-12-2619_21_51.635635/model-00037-1.26371-0.91252-1.52790-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.9311 - loss: 1.2422 - val_categorical_accuracy: 0.7800 - val_loss: 1.5279 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9351 - loss: 1.2272\n",
      "Epoch 38: saving model to model_init_2024-12-2619_21_51.635635/model-00038-1.23766-0.91554-1.45891-0.83000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.9342 - loss: 1.2276 - val_categorical_accuracy: 0.8300 - val_loss: 1.4589 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9174 - loss: 1.2245\n",
      "Epoch 39: saving model to model_init_2024-12-2619_21_51.635635/model-00039-1.23152-0.90950-1.48718-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9171 - loss: 1.2248 - val_categorical_accuracy: 0.7800 - val_loss: 1.4872 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9391 - loss: 1.1992\n",
      "Epoch 40: saving model to model_init_2024-12-2619_21_51.635635/model-00040-1.20611-0.92911-1.50387-0.77000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - categorical_accuracy: 0.9387 - loss: 1.1995 - val_categorical_accuracy: 0.7700 - val_loss: 1.5039 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9344 - loss: 1.1790\n",
      "Epoch 41: saving model to model_init_2024-12-2619_21_51.635635/model-00041-1.19545-0.92157-1.53193-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - categorical_accuracy: 0.9339 - loss: 1.1797 - val_categorical_accuracy: 0.7800 - val_loss: 1.5319 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9203 - loss: 1.1846\n",
      "Epoch 42: saving model to model_init_2024-12-2619_21_51.635635/model-00042-1.17806-0.92308-1.41059-0.83000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.9204 - loss: 1.1843 - val_categorical_accuracy: 0.8300 - val_loss: 1.4106 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.9232 - loss: 1.1626\n",
      "Epoch 43: saving model to model_init_2024-12-2619_21_51.635635/model-00043-1.17248-0.92157-1.38427-0.83000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - categorical_accuracy: 0.9231 - loss: 1.1630 - val_categorical_accuracy: 0.8300 - val_loss: 1.3843 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9229 - loss: 1.1372\n",
      "Epoch 44: saving model to model_init_2024-12-2619_21_51.635635/model-00044-1.15909-0.91101-1.44929-0.81000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9225 - loss: 1.1381 - val_categorical_accuracy: 0.8100 - val_loss: 1.4493 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9432 - loss: 1.1247\n",
      "Epoch 45: saving model to model_init_2024-12-2619_21_51.635635/model-00045-1.13914-0.92609-1.40563-0.79000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9425 - loss: 1.1253 - val_categorical_accuracy: 0.7900 - val_loss: 1.4056 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - categorical_accuracy: 0.9533 - loss: 1.1170\n",
      "Epoch 46: saving model to model_init_2024-12-2619_21_51.635635/model-00046-1.12183-0.94268-1.43288-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 6s/step - categorical_accuracy: 0.9528 - loss: 1.1172 - val_categorical_accuracy: 0.7800 - val_loss: 1.4329 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9148 - loss: 1.1111\n",
      "Epoch 47: saving model to model_init_2024-12-2619_21_51.635635/model-00047-1.11682-0.92157-1.37636-0.74000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 6s/step - categorical_accuracy: 0.9151 - loss: 1.1113 - val_categorical_accuracy: 0.7400 - val_loss: 1.3764 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9384 - loss: 1.0903\n",
      "Epoch 48: saving model to model_init_2024-12-2619_21_51.635635/model-00048-1.11137-0.92609-1.39498-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - categorical_accuracy: 0.9378 - loss: 1.0912 - val_categorical_accuracy: 0.8200 - val_loss: 1.3950 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9499 - loss: 1.0676\n",
      "Epoch 49: saving model to model_init_2024-12-2619_21_51.635635/model-00049-1.08096-0.94118-1.46920-0.80000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - categorical_accuracy: 0.9495 - loss: 1.0682 - val_categorical_accuracy: 0.8000 - val_loss: 1.4692 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9328 - loss: 1.0712\n",
      "Epoch 50: saving model to model_init_2024-12-2619_21_51.635635/model-00050-1.07715-0.93363-1.39276-0.77000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - categorical_accuracy: 0.9328 - loss: 1.0714 - val_categorical_accuracy: 0.7700 - val_loss: 1.3928 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1efdc920910>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 93 % and validation accuracy of 77 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 5\n",
    "CNN + LSTM Model with 30 epochs, 30 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 120x120 , adam optimiser with learning rate 0.0001, 20 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 30\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 30\n",
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Dense, Dropout, LSTM, TimeDistributed\n",
    "from tensorflow.keras import Input, regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "# dropout_rate = 0.5\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Input shape: (number of frames, height, width, channels)\n",
    "input_shape = (20, 120, 120, 3)\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# TimeDistributed CNN Layers\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg)), input_shape=input_shape))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# Flatten spatial features\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layers\n",
    "model.add(LSTM(128, return_sequences=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28800</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,811,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │           \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m) │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28800\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m14,811,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,922,949</span> (56.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,922,949\u001b[0m (56.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,922,501</span> (56.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,922,501\u001b[0m (56.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_2(train_path, train_doc, batch_size)\n",
    "val_generator = generator_2(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 23\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 30\n",
      "num_batches =  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1039/4273982213.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m54s\u001b[0m 27s/step - categorical_accuracy: 0.2398 - loss: 13.9791 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1039/4273982213.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 27s/step - categorical_accuracy: 0.2424 - loss: 13.9596num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - categorical_accuracy: 0.2447 - loss: 13.9416 Source path =  Project_data/val ; batch size = 30\n",
      "num_batches =  3\n",
      "num_batches =  3\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2707_52_10.735881/model-00001-13.54548-0.29563-12.55466-0.35000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 27s/step - categorical_accuracy: 0.2468 - loss: 13.9251 - val_categorical_accuracy: 0.3500 - val_loss: 12.5547 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 0.5322 - loss: 11.9925num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - categorical_accuracy: 0.5327 - loss: 11.9732 num_batches =  3\n",
      "\n",
      "Epoch 2: saving model to model_init_2024-12-2707_52_10.735881/model-00002-11.54871-0.54449-10.75422-0.48000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 27s/step - categorical_accuracy: 0.5332 - loss: 11.9556 - val_categorical_accuracy: 0.4800 - val_loss: 10.7542 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 0.6945 - loss: 10.1552num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.6935 - loss: 10.1400 num_batches =  3\n",
      "\n",
      "Epoch 3: saving model to model_init_2024-12-2707_52_10.735881/model-00003-9.80537-0.67119-9.26200-0.34000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 27s/step - categorical_accuracy: 0.6925 - loss: 10.1260 - val_categorical_accuracy: 0.3400 - val_loss: 9.2620 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 0.7314 - loss: 8.6707num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.7323 - loss: 8.6580 num_batches =  3\n",
      "\n",
      "Epoch 4: saving model to model_init_2024-12-2707_52_10.735881/model-00004-8.37961-0.75113-8.20046-0.43000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 27s/step - categorical_accuracy: 0.7331 - loss: 8.6464 - val_categorical_accuracy: 0.4300 - val_loss: 8.2005 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 27s/step - categorical_accuracy: 0.8147 - loss: 7.4817num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - categorical_accuracy: 0.8154 - loss: 7.4720 num_batches =  3\n",
      "\n",
      "Epoch 5: saving model to model_init_2024-12-2707_52_10.735881/model-00005-7.25808-0.82956-7.25451-0.53000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 26s/step - categorical_accuracy: 0.8159 - loss: 7.4630 - val_categorical_accuracy: 0.5300 - val_loss: 7.2545 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 0.8796 - loss: 6.5644num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.8790 - loss: 6.5573 num_batches =  3\n",
      "\n",
      "Epoch 6: saving model to model_init_2024-12-2707_52_10.735881/model-00006-6.40076-0.86576-6.50836-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 28s/step - categorical_accuracy: 0.8785 - loss: 6.5508 - val_categorical_accuracy: 0.5600 - val_loss: 6.5084 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 0.9201 - loss: 5.8362num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9205 - loss: 5.8306 num_batches =  3\n",
      "\n",
      "Epoch 7: saving model to model_init_2024-12-2707_52_10.735881/model-00007-5.70793-0.93062-6.11589-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 28s/step - categorical_accuracy: 0.9210 - loss: 5.8255 - val_categorical_accuracy: 0.5700 - val_loss: 6.1159 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 0.9703 - loss: 5.2527num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9698 - loss: 5.2485 num_batches =  3\n",
      "\n",
      "Epoch 8: saving model to model_init_2024-12-2707_52_10.735881/model-00008-5.15701-0.95928-5.88219-0.44000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 28s/step - categorical_accuracy: 0.9694 - loss: 5.2447 - val_categorical_accuracy: 0.4400 - val_loss: 5.8822 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 29s/step - categorical_accuracy: 0.9722 - loss: 4.8008num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9723 - loss: 4.7972 num_batches =  3\n",
      "\n",
      "Epoch 9: saving model to model_init_2024-12-2707_52_10.735881/model-00009-4.71894-0.97436-5.36712-0.50000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 28s/step - categorical_accuracy: 0.9723 - loss: 4.7940 - val_categorical_accuracy: 0.5000 - val_loss: 5.3671 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 0.9916 - loss: 4.3951num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9915 - loss: 4.3922 num_batches =  3\n",
      "\n",
      "Epoch 10: saving model to model_init_2024-12-2707_52_10.735881/model-00010-4.32780-0.98793-5.10594-0.52000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 27s/step - categorical_accuracy: 0.9913 - loss: 4.3895 - val_categorical_accuracy: 0.5200 - val_loss: 5.1059 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 0.9885 - loss: 4.0693num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9886 - loss: 4.0666 num_batches =  3\n",
      "\n",
      "Epoch 11: saving model to model_init_2024-12-2707_52_10.735881/model-00011-4.00531-0.99095-4.80544-0.62000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 27s/step - categorical_accuracy: 0.9887 - loss: 4.0640 - val_categorical_accuracy: 0.6200 - val_loss: 4.8054 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 0.9990 - loss: 3.7958num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9987 - loss: 3.7938 num_batches =  3\n",
      "\n",
      "Epoch 12: saving model to model_init_2024-12-2707_52_10.735881/model-00012-3.75073-0.99246-4.63551-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 27s/step - categorical_accuracy: 0.9984 - loss: 3.7920 - val_categorical_accuracy: 0.5500 - val_loss: 4.6355 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 3.5564num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 3.5547 num_batches =  3\n",
      "\n",
      "Epoch 13: saving model to model_init_2024-12-2707_52_10.735881/model-00013-3.51909-0.99548-4.60372-0.51000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 3.5533 - val_categorical_accuracy: 0.5100 - val_loss: 4.6037 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 3.3423num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 3.3410 num_batches =  3\n",
      "\n",
      "Epoch 14: saving model to model_init_2024-12-2707_52_10.735881/model-00014-3.31146-0.99698-4.35283-0.53000.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 3.3397 - val_categorical_accuracy: 0.5300 - val_loss: 4.3528 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 3.1696num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 3.1682 num_batches =  3\n",
      "\n",
      "Epoch 15: saving model to model_init_2024-12-2707_52_10.735881/model-00015-3.13556-0.99698-4.00208-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 3.1668 - val_categorical_accuracy: 0.5500 - val_loss: 4.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 3.0030num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 3.0017 num_batches =  3\n",
      "\n",
      "Epoch 16: saving model to model_init_2024-12-2707_52_10.735881/model-00016-2.97235-0.99849-3.99457-0.52000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 3.0005 - val_categorical_accuracy: 0.5200 - val_loss: 3.9946 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m29s\u001b[0m 29s/step - categorical_accuracy: 1.0000 - loss: 2.8533num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - categorical_accuracy: 0.9999 - loss: 2.8523 num_batches =  3\n",
      "\n",
      "Epoch 17: saving model to model_init_2024-12-2707_52_10.735881/model-00017-2.82840-0.99698-3.98050-0.53000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 28s/step - categorical_accuracy: 0.9997 - loss: 2.8513 - val_categorical_accuracy: 0.5300 - val_loss: 3.9805 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.7133num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 2.7124 num_batches =  3\n",
      "\n",
      "Epoch 18: saving model to model_init_2024-12-2707_52_10.735881/model-00018-2.69319-0.99698-3.72020-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 2.7116 - val_categorical_accuracy: 0.5700 - val_loss: 3.7202 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.5862num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 2.5854 num_batches =  3\n",
      "\n",
      "Epoch 19: saving model to model_init_2024-12-2707_52_10.735881/model-00019-2.56623-0.99698-3.57254-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 2.5846 - val_categorical_accuracy: 0.5600 - val_loss: 3.5725 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.4692num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 2.4684 num_batches =  3\n",
      "\n",
      "Epoch 20: saving model to model_init_2024-12-2707_52_10.735881/model-00020-2.45114-0.99548-3.51771-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 2.4677 - val_categorical_accuracy: 0.5500 - val_loss: 3.5177 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.3565num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 2.3558 num_batches =  3\n",
      "\n",
      "Epoch 21: saving model to model_init_2024-12-2707_52_10.735881/model-00021-2.34059-0.99548-3.47346-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 2.3552 - val_categorical_accuracy: 0.5700 - val_loss: 3.4735 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.2521num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 2.2515 num_batches =  3\n",
      "\n",
      "Epoch 22: saving model to model_init_2024-12-2707_52_10.735881/model-00022-2.23723-0.99698-3.20244-0.59000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 2.2509 - val_categorical_accuracy: 0.5900 - val_loss: 3.2024 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.1563num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 1.0000 - loss: 2.1558 num_batches =  3\n",
      "\n",
      "Epoch 23: saving model to model_init_2024-12-2707_52_10.735881/model-00023-2.14448-1.00000-3.11789-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 27s/step - categorical_accuracy: 1.0000 - loss: 2.1553 - val_categorical_accuracy: 0.5700 - val_loss: 3.1179 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 2.0673num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 2.0667 num_batches =  3\n",
      "\n",
      "Epoch 24: saving model to model_init_2024-12-2707_52_10.735881/model-00024-2.05374-0.99548-3.02045-0.63000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 2.0662 - val_categorical_accuracy: 0.6300 - val_loss: 3.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m27s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.9850num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 1.9846 num_batches =  3\n",
      "\n",
      "Epoch 25: saving model to model_init_2024-12-2707_52_10.735881/model-00025-1.97705-0.99548-3.13300-0.53000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 1.9843 - val_categorical_accuracy: 0.5300 - val_loss: 3.1330 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.9048num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 1.9043 num_batches =  3\n",
      "\n",
      "Epoch 26: saving model to model_init_2024-12-2707_52_10.735881/model-00026-1.89352-0.99698-2.98237-0.61000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 1.9038 - val_categorical_accuracy: 0.6100 - val_loss: 2.9824 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.8208num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 1.8204 num_batches =  3\n",
      "\n",
      "Epoch 27: saving model to model_init_2024-12-2707_52_10.735881/model-00027-1.81177-0.99548-2.92726-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 1.8201 - val_categorical_accuracy: 0.5800 - val_loss: 2.9273 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.7502num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 1.7498 num_batches =  3\n",
      "\n",
      "Epoch 28: saving model to model_init_2024-12-2707_52_10.735881/model-00028-1.74021-0.99548-2.96271-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 1.7494 - val_categorical_accuracy: 0.5400 - val_loss: 2.9627 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.6780num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9998 - loss: 1.6777 num_batches =  3\n",
      "\n",
      "Epoch 29: saving model to model_init_2024-12-2707_52_10.735881/model-00029-1.67073-0.99548-2.73193-0.60000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 27s/step - categorical_accuracy: 0.9996 - loss: 1.6774 - val_categorical_accuracy: 0.6000 - val_loss: 2.7319 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m22/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 28s/step - categorical_accuracy: 1.0000 - loss: 1.6131num_batches =  22\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - categorical_accuracy: 0.9999 - loss: 1.6127 num_batches =  3\n",
      "\n",
      "Epoch 30: saving model to model_init_2024-12-2707_52_10.735881/model-00030-1.60432-0.99698-2.70143-0.60000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 27s/step - categorical_accuracy: 0.9997 - loss: 1.6124 - val_categorical_accuracy: 0.6000 - val_loss: 2.7014 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x307c71bd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 60 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 6\n",
    "CNN + LSTM Model with 50 epochs, 30 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 160x160 , adam optimiser with learning rate 0.0001, 20 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 50\n"
     ]
    }
   ],
   "source": [
    "train_doc_100 = np.random.permutation(open('Project_data/train_100.csv').readlines())\n",
    "val_doc_50 = np.random.permutation(open('Project_data/val_50.csv').readlines())\n",
    "batch_size = 30\n",
    "num_epochs = 50\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Dense, Dropout, LSTM, TimeDistributed\n",
    "from tensorflow.keras import Input, regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "# dropout_rate = 0.5\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Input shape: (number of frames, height, width, channels)\n",
    "input_shape = (20, 160, 160, 3)\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# TimeDistributed CNN Layers\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg)), input_shape=input_shape))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(l2_reg))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# Flatten spatial features\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layers\n",
    "model.add(LSTM(128, return_sequences=False, kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">26,280,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │           \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m) │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m51200\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m26,280,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,391,749</span> (100.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,391,749\u001b[0m (100.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,391,301</span> (100.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,391,301\u001b[0m (100.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_3(train_path, train_doc_100, batch_size)\n",
    "val_generator = generator_3(val_path, val_doc_50, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 23\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1081/2363037342.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:22\u001b[0m 71s/step - categorical_accuracy: 0.2824 - loss: 14.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1081/2363037342.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68s/step - categorical_accuracy: 0.2858 - loss: 13.9575  Source path =  Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2714_36_52.054119/model-00001-13.45822-0.32127-12.18563-0.37000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1596s\u001b[0m 69s/step - categorical_accuracy: 0.2873 - loss: 13.9367 - val_categorical_accuracy: 0.3700 - val_loss: 12.1856 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.5515 - loss: 11.5095  \n",
      "Epoch 2: saving model to model_init_2024-12-2714_36_52.054119/model-00002-11.01347-0.52640-9.95407-0.50000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1606s\u001b[0m 70s/step - categorical_accuracy: 0.5505 - loss: 11.4888 - val_categorical_accuracy: 0.5000 - val_loss: 9.9541 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.6552 - loss: 9.3750  \n",
      "Epoch 3: saving model to model_init_2024-12-2714_36_52.054119/model-00003-8.98669-0.66516-8.33037-0.47500.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1602s\u001b[0m 70s/step - categorical_accuracy: 0.6556 - loss: 9.3588 - val_categorical_accuracy: 0.4750 - val_loss: 8.3304 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.7664 - loss: 7.7415  \n",
      "Epoch 4: saving model to model_init_2024-12-2714_36_52.054119/model-00004-7.48741-0.76320-7.21906-0.45000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 69s/step - categorical_accuracy: 0.7662 - loss: 7.7309 - val_categorical_accuracy: 0.4500 - val_loss: 7.2191 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.8480 - loss: 6.5695  \n",
      "Epoch 5: saving model to model_init_2024-12-2714_36_52.054119/model-00005-6.38463-0.83710-6.44647-0.38333.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 69s/step - categorical_accuracy: 0.8476 - loss: 6.5618 - val_categorical_accuracy: 0.3833 - val_loss: 6.4465 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.8712 - loss: 5.7684  \n",
      "Epoch 6: saving model to model_init_2024-12-2714_36_52.054119/model-00006-5.61699-0.87632-5.84005-0.45000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1616s\u001b[0m 70s/step - categorical_accuracy: 0.8714 - loss: 5.7621 - val_categorical_accuracy: 0.4500 - val_loss: 5.8401 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9179 - loss: 5.0954  \n",
      "Epoch 7: saving model to model_init_2024-12-2714_36_52.054119/model-00007-4.99345-0.91252-5.37382-0.46000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1615s\u001b[0m 70s/step - categorical_accuracy: 0.9177 - loss: 5.0911 - val_categorical_accuracy: 0.4600 - val_loss: 5.3738 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9517 - loss: 4.5540  \n",
      "Epoch 8: saving model to model_init_2024-12-2714_36_52.054119/model-00008-4.47638-0.94570-5.01183-0.50000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1614s\u001b[0m 70s/step - categorical_accuracy: 0.9514 - loss: 4.5507 - val_categorical_accuracy: 0.5000 - val_loss: 5.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9641 - loss: 4.1367  \n",
      "Epoch 9: saving model to model_init_2024-12-2714_36_52.054119/model-00009-4.07729-0.95324-4.69604-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1637s\u001b[0m 71s/step - categorical_accuracy: 0.9637 - loss: 4.1343 - val_categorical_accuracy: 0.5400 - val_loss: 4.6960 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9875 - loss: 3.7969  \n",
      "Epoch 10: saving model to model_init_2024-12-2714_36_52.054119/model-00010-3.74201-0.98190-4.47939-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1623s\u001b[0m 70s/step - categorical_accuracy: 0.9873 - loss: 3.7946 - val_categorical_accuracy: 0.5400 - val_loss: 4.4794 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9929 - loss: 3.4701  \n",
      "Epoch 11: saving model to model_init_2024-12-2714_36_52.054119/model-00011-3.43003-0.98793-4.20361-0.52000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1614s\u001b[0m 70s/step - categorical_accuracy: 0.9927 - loss: 3.4684 - val_categorical_accuracy: 0.5200 - val_loss: 4.2036 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9995 - loss: 3.2304  \n",
      "Epoch 12: saving model to model_init_2024-12-2714_36_52.054119/model-00012-3.19069-0.99397-4.15612-0.48000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1620s\u001b[0m 70s/step - categorical_accuracy: 0.9993 - loss: 3.2287 - val_categorical_accuracy: 0.4800 - val_loss: 4.1561 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 3.0180  \n",
      "Epoch 13: saving model to model_init_2024-12-2714_36_52.054119/model-00013-2.98336-0.99397-3.90020-0.53000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 70s/step - categorical_accuracy: 0.9994 - loss: 3.0165 - val_categorical_accuracy: 0.5300 - val_loss: 3.9002 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9987 - loss: 2.8291  \n",
      "Epoch 14: saving model to model_init_2024-12-2714_36_52.054119/model-00014-2.79967-0.99548-3.74378-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 70s/step - categorical_accuracy: 0.9986 - loss: 2.8279 - val_categorical_accuracy: 0.5800 - val_loss: 3.7438 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 2.6693  \n",
      "Epoch 15: saving model to model_init_2024-12-2714_36_52.054119/model-00015-2.64491-0.99849-3.62930-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 2.6683 - val_categorical_accuracy: 0.5700 - val_loss: 3.6293 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 2.5257  \n",
      "Epoch 16: saving model to model_init_2024-12-2714_36_52.054119/model-00016-2.50721-0.99548-3.60293-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 2.5249 - val_categorical_accuracy: 0.5800 - val_loss: 3.6029 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 2.3914  \n",
      "Epoch 17: saving model to model_init_2024-12-2714_36_52.054119/model-00017-2.37661-0.99548-3.45876-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1602s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 2.3908 - val_categorical_accuracy: 0.5500 - val_loss: 3.4588 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 2.2750  \n",
      "Epoch 18: saving model to model_init_2024-12-2714_36_52.054119/model-00018-2.25993-0.99698-3.23211-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 69s/step - categorical_accuracy: 0.9997 - loss: 2.2744 - val_categorical_accuracy: 0.5700 - val_loss: 3.2321 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 2.1730  \n",
      "Epoch 19: saving model to model_init_2024-12-2714_36_52.054119/model-00019-2.15359-0.99698-3.26608-0.57000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1604s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 2.1722 - val_categorical_accuracy: 0.5700 - val_loss: 3.2661 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 2.0665  \n",
      "Epoch 20: saving model to model_init_2024-12-2714_36_52.054119/model-00020-2.05676-0.99548-3.04153-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1599s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 2.0661 - val_categorical_accuracy: 0.5600 - val_loss: 3.0415 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1556s/step - categorical_accuracy: 0.9998 - loss: 1.9749   \n",
      "Epoch 21: saving model to model_init_2024-12-2714_36_52.054119/model-00021-1.96283-0.99548-3.02365-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34311s\u001b[0m 1556s/step - categorical_accuracy: 0.9996 - loss: 1.9744 - val_categorical_accuracy: 0.5800 - val_loss: 3.0236 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 1.8938  \n",
      "Epoch 22: saving model to model_init_2024-12-2714_36_52.054119/model-00022-1.88302-0.99698-3.09984-0.51000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1609s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 1.8933 - val_categorical_accuracy: 0.5100 - val_loss: 3.0998 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.8109  \n",
      "Epoch 23: saving model to model_init_2024-12-2714_36_52.054119/model-00023-1.80108-0.99548-2.91823-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1616s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.8105 - val_categorical_accuracy: 0.5600 - val_loss: 2.9182 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.7355  \n",
      "Epoch 24: saving model to model_init_2024-12-2714_36_52.054119/model-00024-1.72639-0.99548-2.83726-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1610s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.7351 - val_categorical_accuracy: 0.5400 - val_loss: 2.8373 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9999 - loss: 1.6627  \n",
      "Epoch 25: saving model to model_init_2024-12-2714_36_52.054119/model-00025-1.65483-0.99849-2.87424-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1618s\u001b[0m 70s/step - categorical_accuracy: 0.9999 - loss: 1.6624 - val_categorical_accuracy: 0.5600 - val_loss: 2.8742 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9999 - loss: 1.5968  \n",
      "Epoch 26: saving model to model_init_2024-12-2714_36_52.054119/model-00026-1.59000-0.99698-2.83194-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1623s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 1.5965 - val_categorical_accuracy: 0.5500 - val_loss: 2.8319 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9999 - loss: 1.5324  \n",
      "Epoch 27: saving model to model_init_2024-12-2714_36_52.054119/model-00027-1.52595-0.99698-2.55796-0.60000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1623s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 1.5322 - val_categorical_accuracy: 0.6000 - val_loss: 2.5580 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.4705  \n",
      "Epoch 28: saving model to model_init_2024-12-2714_36_52.054119/model-00028-1.46381-0.99548-2.48367-0.54000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1608s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.4702 - val_categorical_accuracy: 0.5400 - val_loss: 2.4837 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.4110  \n",
      "Epoch 29: saving model to model_init_2024-12-2714_36_52.054119/model-00029-1.40768-0.99548-2.56926-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1609s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.4108 - val_categorical_accuracy: 0.5800 - val_loss: 2.5693 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.3585  \n",
      "Epoch 30: saving model to model_init_2024-12-2714_36_52.054119/model-00030-1.35455-0.99548-2.29656-0.63000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1599s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 1.3584 - val_categorical_accuracy: 0.6300 - val_loss: 2.2966 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.3122  \n",
      "Epoch 31: saving model to model_init_2024-12-2714_36_52.054119/model-00031-1.30870-0.99548-2.43911-0.55000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1599s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 1.3121 - val_categorical_accuracy: 0.5500 - val_loss: 2.4391 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.2612  \n",
      "Epoch 32: saving model to model_init_2024-12-2714_36_52.054119/model-00032-1.25893-0.99548-2.33636-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 1.2611 - val_categorical_accuracy: 0.5800 - val_loss: 2.3364 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.2154  \n",
      "Epoch 33: saving model to model_init_2024-12-2714_36_52.054119/model-00033-1.21105-0.99548-2.39802-0.59000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1598s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 1.2152 - val_categorical_accuracy: 0.5900 - val_loss: 2.3980 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.1732  \n",
      "Epoch 34: saving model to model_init_2024-12-2714_36_52.054119/model-00034-1.17526-0.99548-2.63910-0.48000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1599s\u001b[0m 69s/step - categorical_accuracy: 0.9996 - loss: 1.1733 - val_categorical_accuracy: 0.4800 - val_loss: 2.6391 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9940 - loss: 1.1812  \n",
      "Epoch 35: saving model to model_init_2024-12-2714_36_52.054119/model-00035-1.17923-0.99246-2.87947-0.43000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1601s\u001b[0m 69s/step - categorical_accuracy: 0.9939 - loss: 1.1811 - val_categorical_accuracy: 0.4300 - val_loss: 2.8795 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9432 - loss: 1.3333  \n",
      "Epoch 36: saving model to model_init_2024-12-2714_36_52.054119/model-00036-1.32301-0.96078-2.32957-0.56000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1607s\u001b[0m 70s/step - categorical_accuracy: 0.9439 - loss: 1.3329 - val_categorical_accuracy: 0.5600 - val_loss: 2.3296 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9812 - loss: 1.2706  \n",
      "Epoch 37: saving model to model_init_2024-12-2714_36_52.054119/model-00037-1.28479-0.97285-2.56614-0.50000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1610s\u001b[0m 70s/step - categorical_accuracy: 0.9808 - loss: 1.2712 - val_categorical_accuracy: 0.5000 - val_loss: 2.5661 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9914 - loss: 1.2326  \n",
      "Epoch 38: saving model to model_init_2024-12-2714_36_52.054119/model-00038-1.22061-0.99095-2.11267-0.58000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1612s\u001b[0m 70s/step - categorical_accuracy: 0.9914 - loss: 1.2321 - val_categorical_accuracy: 0.5800 - val_loss: 2.1127 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.1382  \n",
      "Epoch 39: saving model to model_init_2024-12-2714_36_52.054119/model-00039-1.12803-0.99548-2.10999-0.66000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1614s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.1378 - val_categorical_accuracy: 0.6600 - val_loss: 2.1100 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 1.0692  \n",
      "Epoch 40: saving model to model_init_2024-12-2714_36_52.054119/model-00040-1.06360-0.99698-2.02115-0.66000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1610s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 1.0690 - val_categorical_accuracy: 0.6600 - val_loss: 2.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 1.0139  \n",
      "Epoch 41: saving model to model_init_2024-12-2714_36_52.054119/model-00041-1.01185-0.99548-2.02747-0.63000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1608s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 1.0138 - val_categorical_accuracy: 0.6300 - val_loss: 2.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71s/step - categorical_accuracy: 0.9998 - loss: 0.9706  \n",
      "Epoch 42: saving model to model_init_2024-12-2714_36_52.054119/model-00042-0.96960-0.99548-1.92730-0.67000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1656s\u001b[0m 72s/step - categorical_accuracy: 0.9996 - loss: 0.9705 - val_categorical_accuracy: 0.6700 - val_loss: 1.9273 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9998 - loss: 0.9340  \n",
      "Epoch 43: saving model to model_init_2024-12-2714_36_52.054119/model-00043-0.93470-0.99548-1.99736-0.64000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1626s\u001b[0m 71s/step - categorical_accuracy: 0.9996 - loss: 0.9341 - val_categorical_accuracy: 0.6400 - val_loss: 1.9974 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 0.9042  \n",
      "Epoch 44: saving model to model_init_2024-12-2714_36_52.054119/model-00044-0.90482-0.99698-1.89404-0.70000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1605s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 0.9042 - val_categorical_accuracy: 0.7000 - val_loss: 1.8940 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 0.8738  \n",
      "Epoch 45: saving model to model_init_2024-12-2714_36_52.054119/model-00045-0.87460-0.99548-1.76445-0.67000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1610s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 0.8739 - val_categorical_accuracy: 0.6700 - val_loss: 1.7645 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 0.8443  \n",
      "Epoch 46: saving model to model_init_2024-12-2714_36_52.054119/model-00046-0.84545-0.99548-1.85298-0.61000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1609s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 0.8443 - val_categorical_accuracy: 0.6100 - val_loss: 1.8530 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9999 - loss: 0.8161  \n",
      "Epoch 47: saving model to model_init_2024-12-2714_36_52.054119/model-00047-0.81741-0.99698-1.82424-0.63000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1606s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 0.8161 - val_categorical_accuracy: 0.6300 - val_loss: 1.8242 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9999 - loss: 0.7936  \n",
      "Epoch 48: saving model to model_init_2024-12-2714_36_52.054119/model-00048-0.79444-0.99698-1.68417-0.70000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1617s\u001b[0m 70s/step - categorical_accuracy: 0.9997 - loss: 0.7936 - val_categorical_accuracy: 0.7000 - val_loss: 1.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70s/step - categorical_accuracy: 0.9998 - loss: 0.7667  \n",
      "Epoch 49: saving model to model_init_2024-12-2714_36_52.054119/model-00049-0.76888-0.99548-1.68328-0.68000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1618s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 0.7668 - val_categorical_accuracy: 0.6800 - val_loss: 1.6833 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - categorical_accuracy: 0.9998 - loss: 0.7421  \n",
      "Epoch 50: saving model to model_init_2024-12-2714_36_52.054119/model-00050-0.74455-0.99548-1.66456-0.67000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1612s\u001b[0m 70s/step - categorical_accuracy: 0.9996 - loss: 0.7422 - val_categorical_accuracy: 0.6700 - val_loss: 1.6646 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3107962d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 67 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 7\n",
    "CNN + LSTM Model with 20 epochs, 20 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 160x160 , adam optimiser with learning rate 0.0001, 20 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Input shape: (number of frames, height, width, channels)\n",
    "input_shape = (20, 160, 160, 3)\n",
    "\n",
    "GRU_model = Sequential()\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                          input_shape=(input_shape)))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "\n",
    "GRU_model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "GRU_model.add(GRU(128))\n",
    "\n",
    "GRU_model.add(Dense(128,activation='relu'))\n",
    "\n",
    "GRU_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_10                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_11                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_12                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,965,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │             \u001b[38;5;34m448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │              \u001b[38;5;34m64\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_4 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_5 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_6 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_7 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_8 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_9 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_10                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_11                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_12                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m12800\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m4,965,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,080,677</span> (19.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,080,677\u001b[0m (19.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,080,197</span> (19.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,080,197\u001b[0m (19.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "GRU_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(GRU_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_3(train_path, train_doc, batch_size)\n",
    "val_generator = generator_3(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 34\n",
      "Validation steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data_Final/train ; batch size = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 12s/step - categorical_accuracy: 0.3449 - loss: 1.5167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.3513 - loss: 1.5067 Source path =  Project_data_Final/val ; batch size = 20\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2816_47_18.992975/model-00001-1.34730-0.45400-1.19947-0.52000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 12s/step - categorical_accuracy: 0.3542 - loss: 1.5022 - val_categorical_accuracy: 0.5200 - val_loss: 1.1995 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.8271 - loss: 0.6712 \n",
      "Epoch 2: saving model to model_init_2024-12-2816_47_18.992975/model-00002-0.61812-0.84465-1.16294-0.56000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 11s/step - categorical_accuracy: 0.8276 - loss: 0.6697 - val_categorical_accuracy: 0.5600 - val_loss: 1.1629 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9555 - loss: 0.3274 \n",
      "Epoch 3: saving model to model_init_2024-12-2816_47_18.992975/model-00003-0.29871-0.96531-0.93549-0.70000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 11s/step - categorical_accuracy: 0.9557 - loss: 0.3265 - val_categorical_accuracy: 0.7000 - val_loss: 0.9355 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9976 - loss: 0.1450 \n",
      "Epoch 4: saving model to model_init_2024-12-2816_47_18.992975/model-00004-0.15020-0.99397-1.15728-0.57000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 11s/step - categorical_accuracy: 0.9975 - loss: 0.1452 - val_categorical_accuracy: 0.5700 - val_loss: 1.1573 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9974 - loss: 0.0792 \n",
      "Epoch 5: saving model to model_init_2024-12-2816_47_18.992975/model-00005-0.09765-0.99397-1.00754-0.57000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 11s/step - categorical_accuracy: 0.9973 - loss: 0.0798 - val_categorical_accuracy: 0.5700 - val_loss: 1.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9939 - loss: 0.0623 \n",
      "Epoch 6: saving model to model_init_2024-12-2816_47_18.992975/model-00006-0.05881-0.99698-0.89140-0.67000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 11s/step - categorical_accuracy: 0.9940 - loss: 0.0622 - val_categorical_accuracy: 0.6700 - val_loss: 0.8914 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0418 \n",
      "Epoch 7: saving model to model_init_2024-12-2816_47_18.992975/model-00007-0.05301-0.99548-0.86888-0.69000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0421 - val_categorical_accuracy: 0.6900 - val_loss: 0.8689 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9999 - loss: 0.0365 \n",
      "Epoch 8: saving model to model_init_2024-12-2816_47_18.992975/model-00008-0.04116-0.99548-0.99804-0.63000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0367 - val_categorical_accuracy: 0.6300 - val_loss: 0.9980 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0288 \n",
      "Epoch 9: saving model to model_init_2024-12-2816_47_18.992975/model-00009-0.04008-0.99698-0.99054-0.63000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0291 - val_categorical_accuracy: 0.6300 - val_loss: 0.9905 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0261 \n",
      "Epoch 10: saving model to model_init_2024-12-2816_47_18.992975/model-00010-0.03215-0.99698-1.10601-0.63000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0262 - val_categorical_accuracy: 0.6300 - val_loss: 1.1060 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0192 \n",
      "Epoch 11: saving model to model_init_2024-12-2816_47_18.992975/model-00011-0.02983-0.99548-1.05705-0.62000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0195 - val_categorical_accuracy: 0.6200 - val_loss: 1.0571 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9999 - loss: 0.0172 \n",
      "Epoch 12: saving model to model_init_2024-12-2816_47_18.992975/model-00012-0.02483-0.99698-0.98432-0.65000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0174 - val_categorical_accuracy: 0.6500 - val_loss: 0.9843 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9999 - loss: 0.0156 \n",
      "Epoch 13: saving model to model_init_2024-12-2816_47_18.992975/model-00013-0.02279-0.99548-0.95677-0.64000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0158 - val_categorical_accuracy: 0.6400 - val_loss: 0.9568 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 1.0000 - loss: 0.0142 \n",
      "Epoch 14: saving model to model_init_2024-12-2816_47_18.992975/model-00014-0.01857-0.99849-1.03062-0.66000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0143 - val_categorical_accuracy: 0.6600 - val_loss: 1.0306 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - categorical_accuracy: 0.9999 - loss: 0.0120 \n",
      "Epoch 15: saving model to model_init_2024-12-2816_47_18.992975/model-00015-0.02352-0.99548-1.01565-0.64000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0124 - val_categorical_accuracy: 0.6400 - val_loss: 1.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0105 \n",
      "Epoch 16: saving model to model_init_2024-12-2816_47_18.992975/model-00016-0.01780-0.99698-1.05398-0.62000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0107 - val_categorical_accuracy: 0.6200 - val_loss: 1.0540 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0096 \n",
      "Epoch 17: saving model to model_init_2024-12-2816_47_18.992975/model-00017-0.01844-0.99698-0.87332-0.66000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0099 - val_categorical_accuracy: 0.6600 - val_loss: 0.8733 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0084 \n",
      "Epoch 18: saving model to model_init_2024-12-2816_47_18.992975/model-00018-0.01524-0.99548-1.03326-0.64000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0086 - val_categorical_accuracy: 0.6400 - val_loss: 1.0333 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0085 \n",
      "Epoch 19: saving model to model_init_2024-12-2816_47_18.992975/model-00019-0.01405-0.99698-0.95409-0.65000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 11s/step - categorical_accuracy: 0.9998 - loss: 0.0086 - val_categorical_accuracy: 0.6500 - val_loss: 0.9541 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - categorical_accuracy: 0.9999 - loss: 0.0073 \n",
      "Epoch 20: saving model to model_init_2024-12-2816_47_18.992975/model-00020-0.01920-0.99548-0.98389-0.65000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 11s/step - categorical_accuracy: 0.9997 - loss: 0.0077 - val_categorical_accuracy: 0.6500 - val_loss: 0.9839 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f107e82f90>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 65 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 8 - Adding dropout layer, increasing number of layers\n",
    "CNN + GRU Model with 20 epochs, 30 batch size\n",
    "\n",
    "Without dropouts in Conv layer and with batch normalization\n",
    "\n",
    "Input image size 160x160 , adam optimiser with learning rate 0.0001, 20 images as input out of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 30\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajashekar/Downloads/Softwares/Anaconda/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m GRU_model\u001b[38;5;241m.\u001b[39madd(GRU(\u001b[38;5;241m128\u001b[39m))\n\u001b[1;32m     49\u001b[0m GRU_model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m128\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 50\u001b[0m GRU_model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.25\u001b[39m))\n\u001b[1;32m     52\u001b[0m GRU_model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dropout' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "l2_reg = 0.01\n",
    "num_classes = 5\n",
    "\n",
    "# Input shape: (number of frames, height, width, channels)\n",
    "input_shape = (20, 160, 160, 3)\n",
    "\n",
    "GRU_model = Sequential()\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                          input_shape=(input_shape)))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "GRU_model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "GRU_model.add(TimeDistributed(BatchNormalization()))\n",
    "GRU_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "\n",
    "GRU_model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "GRU_model.add(GRU(128))\n",
    "\n",
    "GRU_model.add(Dense(128,activation='relu'))\n",
    "GRU_model.add(Dropout(0.25))\n",
    "\n",
    "GRU_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_61                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_62                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_63                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_64                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_65                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_66                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_67                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_68                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_69                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_70                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_71                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_72                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_73                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_74                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_75                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_76                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_77                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_78                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_79                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_80                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_81                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_82                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_61                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │             \u001b[38;5;34m448\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_62                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_63                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_64                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_65                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_66                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_67                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_68                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_69                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_70                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_71                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_72                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_73                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_74                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_75                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_76                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_77                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_78                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_79                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_80                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_81                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_82                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m99,072\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,285</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m409,285\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">408,357</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m408,357\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> (3.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m928\u001b[0m (3.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "GRU_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(GRU_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_3(train_path, train_doc, batch_size)\n",
    "val_generator = generator_3(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 23\n",
      "Validation steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data_Final/train ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:15\u001b[0m 38s/step - categorical_accuracy: 0.2577 - loss: 1.6297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_31880\\2363037342.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37s/step - categorical_accuracy: 0.2626 - loss: 1.6241 Source path =  Project_data_Final/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2816_47_18.992975/model-00001-1.56560-0.31373-1.41121-0.40000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 38s/step - categorical_accuracy: 0.2647 - loss: 1.6217 - val_categorical_accuracy: 0.4000 - val_loss: 1.4112 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41s/step - categorical_accuracy: 0.5078 - loss: 1.2675 \n",
      "Epoch 2: saving model to model_init_2024-12-2816_47_18.992975/model-00002-1.23144-0.52338-1.41407-0.35833.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m966s\u001b[0m 41s/step - categorical_accuracy: 0.5084 - loss: 1.2660 - val_categorical_accuracy: 0.3583 - val_loss: 1.4141 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38s/step - categorical_accuracy: 0.6811 - loss: 0.9955 \n",
      "Epoch 3: saving model to model_init_2024-12-2816_47_18.992975/model-00003-1.00692-0.67270-1.47642-0.36667.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m911s\u001b[0m 40s/step - categorical_accuracy: 0.6807 - loss: 0.9960 - val_categorical_accuracy: 0.3667 - val_loss: 1.4764 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43s/step - categorical_accuracy: 0.7714 - loss: 0.8351 \n",
      "Epoch 4: saving model to model_init_2024-12-2816_47_18.992975/model-00004-0.82461-0.77074-1.41916-0.38000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1030s\u001b[0m 44s/step - categorical_accuracy: 0.7714 - loss: 0.8346 - val_categorical_accuracy: 0.3800 - val_loss: 1.4192 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - categorical_accuracy: 0.8621 - loss: 0.6538 \n",
      "Epoch 5: saving model to model_init_2024-12-2816_47_18.992975/model-00005-0.64264-0.86124-1.53507-0.38000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1132s\u001b[0m 50s/step - categorical_accuracy: 0.8621 - loss: 0.6534 - val_categorical_accuracy: 0.3800 - val_loss: 1.5351 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - categorical_accuracy: 0.8806 - loss: 0.5364 \n",
      "Epoch 6: saving model to model_init_2024-12-2816_47_18.992975/model-00006-0.53464-0.88084-1.37964-0.43333.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 43s/step - categorical_accuracy: 0.8807 - loss: 0.5364 - val_categorical_accuracy: 0.4333 - val_loss: 1.3796 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38s/step - categorical_accuracy: 0.9322 - loss: 0.4299 \n",
      "Epoch 7: saving model to model_init_2024-12-2816_47_18.992975/model-00007-0.41886-0.92459-1.42500-0.45000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 39s/step - categorical_accuracy: 0.9319 - loss: 0.4294 - val_categorical_accuracy: 0.4500 - val_loss: 1.4250 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - categorical_accuracy: 0.9339 - loss: 0.3547 \n",
      "Epoch 8: saving model to model_init_2024-12-2816_47_18.992975/model-00008-0.34695-0.93967-1.61362-0.42000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 43s/step - categorical_accuracy: 0.9341 - loss: 0.3544 - val_categorical_accuracy: 0.4200 - val_loss: 1.6136 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44s/step - categorical_accuracy: 0.9808 - loss: 0.2736 \n",
      "Epoch 9: saving model to model_init_2024-12-2816_47_18.992975/model-00009-0.27979-0.97134-1.67613-0.40000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1038s\u001b[0m 45s/step - categorical_accuracy: 0.9804 - loss: 0.2739 - val_categorical_accuracy: 0.4000 - val_loss: 1.6761 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - categorical_accuracy: 0.9813 - loss: 0.2220 \n",
      "Epoch 10: saving model to model_init_2024-12-2816_47_18.992975/model-00010-0.23256-0.97888-1.33672-0.46667.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 43s/step - categorical_accuracy: 0.9812 - loss: 0.2225 - val_categorical_accuracy: 0.4667 - val_loss: 1.3367 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38s/step - categorical_accuracy: 0.9894 - loss: 0.1721 \n",
      "Epoch 11: saving model to model_init_2024-12-2816_47_18.992975/model-00011-0.17712-0.98643-1.63246-0.42500.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m883s\u001b[0m 38s/step - categorical_accuracy: 0.9893 - loss: 0.1723 - val_categorical_accuracy: 0.4250 - val_loss: 1.6325 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37s/step - categorical_accuracy: 0.9956 - loss: 0.1340 \n",
      "Epoch 12: saving model to model_init_2024-12-2816_47_18.992975/model-00012-0.13919-0.99095-1.54673-0.49000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m877s\u001b[0m 38s/step - categorical_accuracy: 0.9954 - loss: 0.1342 - val_categorical_accuracy: 0.4900 - val_loss: 1.5467 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36s/step - categorical_accuracy: 0.9988 - loss: 0.1008 \n",
      "Epoch 13: saving model to model_init_2024-12-2816_47_18.992975/model-00013-0.11610-0.99548-1.48076-0.49000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 37s/step - categorical_accuracy: 0.9987 - loss: 0.1014 - val_categorical_accuracy: 0.4900 - val_loss: 1.4808 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39s/step - categorical_accuracy: 0.9977 - loss: 0.1023 \n",
      "Epoch 14: saving model to model_init_2024-12-2816_47_18.992975/model-00014-0.10807-0.99397-1.51126-0.48333.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 40s/step - categorical_accuracy: 0.9975 - loss: 0.1026 - val_categorical_accuracy: 0.4833 - val_loss: 1.5113 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - categorical_accuracy: 0.9990 - loss: 0.0773 \n",
      "Epoch 15: saving model to model_init_2024-12-2816_47_18.992975/model-00015-0.08797-0.99246-1.39534-0.49167.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1145s\u001b[0m 50s/step - categorical_accuracy: 0.9987 - loss: 0.0777 - val_categorical_accuracy: 0.4917 - val_loss: 1.3953 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42s/step - categorical_accuracy: 0.9990 - loss: 0.0788 \n",
      "Epoch 16: saving model to model_init_2024-12-2816_47_18.992975/model-00016-0.08534-0.99548-1.38441-0.53000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1008s\u001b[0m 43s/step - categorical_accuracy: 0.9988 - loss: 0.0791 - val_categorical_accuracy: 0.5300 - val_loss: 1.3844 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48s/step - categorical_accuracy: 0.9993 - loss: 0.0678 \n",
      "Epoch 17: saving model to model_init_2024-12-2816_47_18.992975/model-00017-0.07439-0.99397-1.58481-0.47000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 49s/step - categorical_accuracy: 0.9991 - loss: 0.0681 - val_categorical_accuracy: 0.4700 - val_loss: 1.5848 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48s/step - categorical_accuracy: 0.9994 - loss: 0.0597 \n",
      "Epoch 18: saving model to model_init_2024-12-2816_47_18.992975/model-00018-0.06655-0.99548-1.60323-0.45000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1110s\u001b[0m 49s/step - categorical_accuracy: 0.9992 - loss: 0.0600 - val_categorical_accuracy: 0.4500 - val_loss: 1.6032 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - categorical_accuracy: 0.9998 - loss: 0.0496 \n",
      "Epoch 19: saving model to model_init_2024-12-2816_47_18.992975/model-00019-0.06323-0.99548-1.58570-0.48333.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1188s\u001b[0m 50s/step - categorical_accuracy: 0.9996 - loss: 0.0502 - val_categorical_accuracy: 0.4833 - val_loss: 1.5857 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43s/step - categorical_accuracy: 0.9998 - loss: 0.0478 \n",
      "Epoch 20: saving model to model_init_2024-12-2816_47_18.992975/model-00020-0.05441-0.99548-1.40730-0.48000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1033s\u001b[0m 44s/step - categorical_accuracy: 0.9996 - loss: 0.0481 - val_categorical_accuracy: 0.4800 - val_loss: 1.4073 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f59b09c710>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 48 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 9 - Pretrained Mobile net, without learning weights, using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 30\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_3(train_path, train_doc, batch_size)\n",
    "val_generator = generator_3(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1081/4291270708.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n"
     ]
    }
   ],
   "source": [
    "# Importing the transfer learning model:\n",
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_24             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_25             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_26             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_27             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,163,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_24             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │     \u001b[38;5;34m3,228,864\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_25             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_26             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_27             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4096\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,163,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,413,317</span> (20.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,413,317\u001b[0m (20.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,182,405</span> (8.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,182,405\u001b[0m (8.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,230,912</span> (12.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,230,912\u001b[0m (12.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Building the model :\n",
    "\n",
    "input_shape = (20,160,160,3)\n",
    "        \n",
    "mobileNetModel= Sequential()\n",
    "mobileNetModel.add(TimeDistributed(mobilenet_transfer,input_shape=(input_shape)))\n",
    "\n",
    "\n",
    "for layer in mobileNetModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "mobileNetModel.add(TimeDistributed(BatchNormalization()))\n",
    "mobileNetModel.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "mobileNetModel.add(TimeDistributed(Flatten()))\n",
    "\n",
    "mobileNetModel.add(LSTM(128))\n",
    "mobileNetModel.add(Dropout(0.25))\n",
    "\n",
    "mobileNetModel.add(Dense(128,activation='relu'))\n",
    "mobileNetModel.add(Dropout(0.25))\n",
    "\n",
    "mobileNetModel.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "optimiser = optimizers.Adam()\n",
    "mobileNetModel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (mobileNetModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1081/2363037342.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 3s/step - categorical_accuracy: 0.3419 - loss: 1.4811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/mw8md0ks7rsdgy45pvbb9cgw0000gn/T/ipykernel_1081/2363037342.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - categorical_accuracy: 0.3509 - loss: 1.4643Source path =  Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-2914_16_28.560001/model-00001-1.28836-0.44495-0.92080-0.69000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - categorical_accuracy: 0.3548 - loss: 1.4570 - val_categorical_accuracy: 0.6900 - val_loss: 0.9208 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.7857 - loss: 0.7050\n",
      "Epoch 2: saving model to model_init_2024-12-2914_16_28.560001/model-00002-0.67111-0.77526-0.65101-0.73000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - categorical_accuracy: 0.7853 - loss: 0.7036 - val_categorical_accuracy: 0.7300 - val_loss: 0.6510 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.8507 - loss: 0.4919\n",
      "Epoch 3: saving model to model_init_2024-12-2914_16_28.560001/model-00003-0.44830-0.86576-0.60876-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - categorical_accuracy: 0.8514 - loss: 0.4901 - val_categorical_accuracy: 0.7800 - val_loss: 0.6088 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9125 - loss: 0.3210\n",
      "Epoch 4: saving model to model_init_2024-12-2914_16_28.560001/model-00004-0.28095-0.93062-0.51915-0.75000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3s/step - categorical_accuracy: 0.9132 - loss: 0.3193 - val_categorical_accuracy: 0.7500 - val_loss: 0.5192 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9563 - loss: 0.1752\n",
      "Epoch 5: saving model to model_init_2024-12-2914_16_28.560001/model-00005-0.19142-0.94872-0.50642-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - categorical_accuracy: 0.9560 - loss: 0.1759 - val_categorical_accuracy: 0.7800 - val_loss: 0.5064 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9616 - loss: 0.1344\n",
      "Epoch 6: saving model to model_init_2024-12-2914_16_28.560001/model-00006-0.13853-0.96078-0.47062-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - categorical_accuracy: 0.9616 - loss: 0.1346 - val_categorical_accuracy: 0.8200 - val_loss: 0.4706 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9965 - loss: 0.0729\n",
      "Epoch 7: saving model to model_init_2024-12-2914_16_28.560001/model-00007-0.08909-0.98793-0.64029-0.74000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - categorical_accuracy: 0.9962 - loss: 0.0736 - val_categorical_accuracy: 0.7400 - val_loss: 0.6403 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9696 - loss: 0.0923\n",
      "Epoch 8: saving model to model_init_2024-12-2914_16_28.560001/model-00008-0.09192-0.97587-0.60867-0.74000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - categorical_accuracy: 0.9698 - loss: 0.0923 - val_categorical_accuracy: 0.7400 - val_loss: 0.6087 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9950 - loss: 0.0395\n",
      "Epoch 9: saving model to model_init_2024-12-2914_16_28.560001/model-00009-0.04704-0.98944-0.57411-0.79000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - categorical_accuracy: 0.9948 - loss: 0.0398 - val_categorical_accuracy: 0.7900 - val_loss: 0.5741 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9998 - loss: 0.0207\n",
      "Epoch 10: saving model to model_init_2024-12-2914_16_28.560001/model-00010-0.03463-0.99548-0.61148-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - categorical_accuracy: 0.9996 - loss: 0.0213 - val_categorical_accuracy: 0.7800 - val_loss: 0.6115 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9999 - loss: 0.0213\n",
      "Epoch 11: saving model to model_init_2024-12-2914_16_28.560001/model-00011-0.02777-0.99698-0.61353-0.76000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - categorical_accuracy: 0.9997 - loss: 0.0216 - val_categorical_accuracy: 0.7600 - val_loss: 0.6135 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9966 - loss: 0.0183\n",
      "Epoch 12: saving model to model_init_2024-12-2914_16_28.560001/model-00012-0.02383-0.99548-0.70994-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - categorical_accuracy: 0.9966 - loss: 0.0185 - val_categorical_accuracy: 0.7800 - val_loss: 0.7099 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9999 - loss: 0.0186\n",
      "Epoch 13: saving model to model_init_2024-12-2914_16_28.560001/model-00013-0.01943-0.99849-0.67717-0.75000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - categorical_accuracy: 0.9999 - loss: 0.0186 - val_categorical_accuracy: 0.7500 - val_loss: 0.6772 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9998 - loss: 0.0160\n",
      "Epoch 14: saving model to model_init_2024-12-2914_16_28.560001/model-00014-0.02991-0.99548-0.62257-0.82000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - categorical_accuracy: 0.9996 - loss: 0.0165 - val_categorical_accuracy: 0.8200 - val_loss: 0.6226 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9998 - loss: 0.0111\n",
      "Epoch 15: saving model to model_init_2024-12-2914_16_28.560001/model-00015-0.01813-0.99548-0.63807-0.79000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - categorical_accuracy: 0.9996 - loss: 0.0114 - val_categorical_accuracy: 0.7900 - val_loss: 0.6381 - learning_rate: 4.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9977 - loss: 0.0152\n",
      "Epoch 16: saving model to model_init_2024-12-2914_16_28.560001/model-00016-0.02180-0.99397-0.67029-0.76000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - categorical_accuracy: 0.9975 - loss: 0.0155 - val_categorical_accuracy: 0.7600 - val_loss: 0.6703 - learning_rate: 4.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9998 - loss: 0.0104\n",
      "Epoch 17: saving model to model_init_2024-12-2914_16_28.560001/model-00017-0.02276-0.99548-0.67566-0.78000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - categorical_accuracy: 0.9996 - loss: 0.0109 - val_categorical_accuracy: 0.7800 - val_loss: 0.6757 - learning_rate: 4.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9980 - loss: 0.0137\n",
      "Epoch 18: saving model to model_init_2024-12-2914_16_28.560001/model-00018-0.03425-0.99095-0.65691-0.77000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - categorical_accuracy: 0.9977 - loss: 0.0146 - val_categorical_accuracy: 0.7700 - val_loss: 0.6569 - learning_rate: 4.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9999 - loss: 0.0098\n",
      "Epoch 19: saving model to model_init_2024-12-2914_16_28.560001/model-00019-0.01647-0.99698-0.65993-0.79000.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - categorical_accuracy: 0.9997 - loss: 0.0101 - val_categorical_accuracy: 0.7900 - val_loss: 0.6599 - learning_rate: 8.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - categorical_accuracy: 0.9999 - loss: 0.0108\n",
      "Epoch 20: saving model to model_init_2024-12-2914_16_28.560001/model-00020-0.01393-0.99849-0.71122-0.76000.keras\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - categorical_accuracy: 0.9999 - loss: 0.0109 - val_categorical_accuracy: 0.7600 - val_loss: 0.7112 - learning_rate: 8.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x38879c210>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobileNetModel.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have got the training accuarcy of 99 % and validation accuracy of 76 % in the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 10 - Pretrained Mobile net, with learning weights, using GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "train_doc = np.random.permutation(open('Project_data_Final/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data_Final/val.csv').readlines())\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_27636\\4057799317.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "# Input shape: (number of frames, height, width, channels)\n",
    "input_shape = (18, 120, 120, 3)\n",
    "        \n",
    "preTrainedGRU = Sequential()\n",
    "preTrainedGRU.trainable = True\n",
    "\n",
    "preTrainedGRU.add(TimeDistributed(mobilenet_transfer,input_shape=(input_shape)))\n",
    "\n",
    "\n",
    "preTrainedGRU.add(TimeDistributed(BatchNormalization()))\n",
    "preTrainedGRU.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "preTrainedGRU.add(TimeDistributed(Flatten()))\n",
    "\n",
    "preTrainedGRU.add(GRU(128))\n",
    "preTrainedGRU.add(Dropout(0.25))\n",
    "\n",
    "preTrainedGRU.add(Dense(128,activation='relu'))\n",
    "preTrainedGRU.add(Dropout(0.25))\n",
    "\n",
    "preTrainedGRU.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_12                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_13                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_14                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_15                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">443,136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_12                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │       \u001b[38;5;34m3,228,864\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_13                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │           \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_14                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_15                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m443,136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,693,253</span> (14.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,693,253\u001b[0m (14.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,669,317</span> (14.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,669,317\u001b[0m (14.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,936</span> (93.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,936\u001b[0m (93.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with an optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.0001)  # You can experiment with the learning rate\n",
    "preTrainedGRU.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary to check the total number of parameters\n",
    "print(preTrainedGRU.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_2(train_path, train_doc, batch_size)\n",
    "val_generator = generator_2(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 34\n",
      "Validation steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print('Steps per epoch:', steps_per_epoch)\n",
    "print('Validation steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data_Final/train ; batch size = 20\n",
      "num_batches =  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_27636\\4273982213.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image using imageio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 8s/step - categorical_accuracy: 0.2378 - loss: 1.7694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upujaari\\AppData\\Local\\Temp\\ipykernel_27636\\4273982213.py:59: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_path).astype(np.float32)  # Read the image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - categorical_accuracy: 0.2396 - loss: 1.7637Source path =  Project_data_Final/val ; batch size = 20\n",
      "num_batches =  5\n",
      "num_batches =  5\n",
      "\n",
      "Epoch 1: saving model to model_init_2024-12-3014_08_30.722141/model-00001-1.67187-0.26697-1.24460-0.56000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 9s/step - categorical_accuracy: 0.2403 - loss: 1.7610 - val_categorical_accuracy: 0.5600 - val_loss: 1.2446 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 7s/step - categorical_accuracy: 0.6114 - loss: 1.1226num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - categorical_accuracy: 0.6111 - loss: 1.1202num_batches =  5\n",
      "\n",
      "Epoch 2: saving model to model_init_2024-12-3014_08_30.722141/model-00002-1.08280-0.60633-0.99587-0.66000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 7s/step - categorical_accuracy: 0.6110 - loss: 1.1191 - val_categorical_accuracy: 0.6600 - val_loss: 0.9959 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 7s/step - categorical_accuracy: 0.7348 - loss: 0.8367num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - categorical_accuracy: 0.7351 - loss: 0.8339num_batches =  5\n",
      "\n",
      "Epoch 3: saving model to model_init_2024-12-3014_08_30.722141/model-00003-0.79318-0.73906-0.80122-0.73000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 7s/step - categorical_accuracy: 0.7352 - loss: 0.8328 - val_categorical_accuracy: 0.7300 - val_loss: 0.8012 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 7s/step - categorical_accuracy: 0.8664 - loss: 0.5468num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - categorical_accuracy: 0.8656 - loss: 0.5464num_batches =  5\n",
      "\n",
      "Epoch 4: saving model to model_init_2024-12-3014_08_30.722141/model-00004-0.54308-0.85068-0.73605-0.71000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - categorical_accuracy: 0.8652 - loss: 0.5463 - val_categorical_accuracy: 0.7100 - val_loss: 0.7360 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9053 - loss: 0.4409num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9054 - loss: 0.4402num_batches =  5\n",
      "\n",
      "Epoch 5: saving model to model_init_2024-12-3014_08_30.722141/model-00005-0.43689-0.90498-0.64633-0.70000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 6s/step - categorical_accuracy: 0.9054 - loss: 0.4401 - val_categorical_accuracy: 0.7000 - val_loss: 0.6463 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9435 - loss: 0.3223num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9435 - loss: 0.3223num_batches =  5\n",
      "\n",
      "Epoch 6: saving model to model_init_2024-12-3014_08_30.722141/model-00006-0.32819-0.94118-0.54858-0.76000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 6s/step - categorical_accuracy: 0.9434 - loss: 0.3225 - val_categorical_accuracy: 0.7600 - val_loss: 0.5486 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9507 - loss: 0.2709num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9518 - loss: 0.2693num_batches =  5\n",
      "\n",
      "Epoch 7: saving model to model_init_2024-12-3014_08_30.722141/model-00007-0.24606-0.96833-0.58333-0.75000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 6s/step - categorical_accuracy: 0.9522 - loss: 0.2686 - val_categorical_accuracy: 0.7500 - val_loss: 0.5833 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9737 - loss: 0.1848num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9736 - loss: 0.1849num_batches =  5\n",
      "\n",
      "Epoch 8: saving model to model_init_2024-12-3014_08_30.722141/model-00008-0.18751-0.97134-0.52964-0.79000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7s/step - categorical_accuracy: 0.9736 - loss: 0.1850 - val_categorical_accuracy: 0.7900 - val_loss: 0.5296 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9851 - loss: 0.1359num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9850 - loss: 0.1360num_batches =  5\n",
      "\n",
      "Epoch 9: saving model to model_init_2024-12-3014_08_30.722141/model-00009-0.14349-0.98190-0.49674-0.83000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 7s/step - categorical_accuracy: 0.9849 - loss: 0.1362 - val_categorical_accuracy: 0.8300 - val_loss: 0.4967 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9947 - loss: 0.1317num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9945 - loss: 0.1312num_batches =  5\n",
      "\n",
      "Epoch 10: saving model to model_init_2024-12-3014_08_30.722141/model-00010-0.12607-0.99095-0.55879-0.76000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 6s/step - categorical_accuracy: 0.9944 - loss: 0.1311 - val_categorical_accuracy: 0.7600 - val_loss: 0.5588 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9911 - loss: 0.0793num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9910 - loss: 0.0799num_batches =  5\n",
      "\n",
      "Epoch 11: saving model to model_init_2024-12-3014_08_30.722141/model-00011-0.09345-0.98793-0.41933-0.84000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 6s/step - categorical_accuracy: 0.9909 - loss: 0.0803 - val_categorical_accuracy: 0.8400 - val_loss: 0.4193 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9984 - loss: 0.0750num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9982 - loss: 0.0753num_batches =  5\n",
      "\n",
      "Epoch 12: saving model to model_init_2024-12-3014_08_30.722141/model-00012-0.08259-0.99246-0.39237-0.86000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 6s/step - categorical_accuracy: 0.9980 - loss: 0.0755 - val_categorical_accuracy: 0.8600 - val_loss: 0.3924 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 6s/step - categorical_accuracy: 0.9974 - loss: 0.0767num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9971 - loss: 0.0768num_batches =  5\n",
      "\n",
      "Epoch 13: saving model to model_init_2024-12-3014_08_30.722141/model-00013-0.08272-0.98944-0.46747-0.83000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 6s/step - categorical_accuracy: 0.9969 - loss: 0.0769 - val_categorical_accuracy: 0.8300 - val_loss: 0.4675 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9968 - loss: 0.0542num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9967 - loss: 0.0545num_batches =  5\n",
      "\n",
      "Epoch 14: saving model to model_init_2024-12-3014_08_30.722141/model-00014-0.06409-0.99397-0.44611-0.83000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 6s/step - categorical_accuracy: 0.9967 - loss: 0.0548 - val_categorical_accuracy: 0.8300 - val_loss: 0.4461 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 6s/step - categorical_accuracy: 0.9996 - loss: 0.0470num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9994 - loss: 0.0473num_batches =  5\n",
      "\n",
      "Epoch 15: saving model to model_init_2024-12-3014_08_30.722141/model-00015-0.05588-0.99397-0.42485-0.84000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 6s/step - categorical_accuracy: 0.9993 - loss: 0.0476 - val_categorical_accuracy: 0.8400 - val_loss: 0.4249 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9954 - loss: 0.0438num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9954 - loss: 0.0442num_batches =  5\n",
      "\n",
      "Epoch 16: saving model to model_init_2024-12-3014_08_30.722141/model-00016-0.05860-0.99246-0.47352-0.81000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 6s/step - categorical_accuracy: 0.9953 - loss: 0.0447 - val_categorical_accuracy: 0.8100 - val_loss: 0.4735 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9994 - loss: 0.0339num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9992 - loss: 0.0343num_batches =  5\n",
      "\n",
      "Epoch 17: saving model to model_init_2024-12-3014_08_30.722141/model-00017-0.04516-0.99397-0.33437-0.85000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 6s/step - categorical_accuracy: 0.9991 - loss: 0.0346 - val_categorical_accuracy: 0.8500 - val_loss: 0.3344 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9994 - loss: 0.0330num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9992 - loss: 0.0334num_batches =  5\n",
      "\n",
      "Epoch 18: saving model to model_init_2024-12-3014_08_30.722141/model-00018-0.04556-0.99548-0.41424-0.83000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 6s/step - categorical_accuracy: 0.9991 - loss: 0.0338 - val_categorical_accuracy: 0.8300 - val_loss: 0.4142 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 0.9989 - loss: 0.0320num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9988 - loss: 0.0324num_batches =  5\n",
      "\n",
      "Epoch 19: saving model to model_init_2024-12-3014_08_30.722141/model-00019-0.04216-0.99397-0.41917-0.88000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 6s/step - categorical_accuracy: 0.9986 - loss: 0.0327 - val_categorical_accuracy: 0.8800 - val_loss: 0.4192 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m32/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - categorical_accuracy: 1.0000 - loss: 0.0305num_batches =  33\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - categorical_accuracy: 0.9999 - loss: 0.0308num_batches =  5\n",
      "\n",
      "Epoch 20: saving model to model_init_2024-12-3014_08_30.722141/model-00020-0.04169-0.99548-0.35069-0.89000.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 6s/step - categorical_accuracy: 0.9997 - loss: 0.0311 - val_categorical_accuracy: 0.8900 - val_loss: 0.3507 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2accff3ef10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preTrainedGRU.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
